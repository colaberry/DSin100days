{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s1",
     "content",
     "l1"
    ]
   },
   "source": [
    "# Introduction to Linear Regression\n",
    "Linear regression is a supervised learning algorithm. Given a single feature, a line is fit that best predicts the independent variable. When many features are involved, a hyperplane is fit that minimizes the error between predicted values and the ground truth. Given an input vector Xn = (X1, X2, ..., Xn) that we want to use to predict the output y, the regression equation is given by:\n",
    "\n",
    "$$y=\\beta_0 + \\sum_{i=1}^nX_i\\beta_i$$\n",
    "\n",
    "As you can see below, the line that minimized the Mean Squared Distance (MSE) is the best fit. Linear Regression is a statistical technique to determine that line.\n",
    "\n",
    "<img src=\"../images/linear_regression.png\", style=\"width: 700px;\"> \n",
    "\n",
    "Regression can also involve fitting polynomials as shown below:\n",
    "\n",
    "<img src=\"../images/curve_fitting.png\", style=\"width: 700px;\"> \n",
    "\n",
    "The errors are reduced by minimizing the error squared, where error is the difference between predicted values and the target values. The linear regression course is organized as:\n",
    "- Study of Boston Housing Price dataset.\n",
    "- EDA - Scatter plots, joint plots\n",
    "- Categorical variables\n",
    "- Regression using Statsmodels\n",
    "- Improving the fit \n",
    "  - R-squared\n",
    "  - P-values\n",
    "  - Multi-collinearity\n",
    "- Regression using Scikit-Learn\n",
    "- Lasso \n",
    "- Ridge\n",
    "- Cross-Validation \n",
    "\n",
    "\n",
    "# Instructions\n",
    "\n",
    "Boston dataset can be loaded from the datasets in Scikit-Learn with the command load_boston(). To work with linear regression datasets, we need the libraries numpy, pandas and seaborn. For modeling, we would need statsmodels or sklearn. sklearn has datasets property which facilitates easy loading of popular datasets such as the Boston Housing price dataset. You can use the load_boston() function to load the datasets. The features are available in feature_names list. We can feed this data into a dataframe to use statsmodels or sklearn for regression modeling. \n",
    "\n",
    "\n",
    "- Slice the top 10 rows of the boston_data dataframe and assign it to boston_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s1",
     "ce",
     "l1"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#Set graph fonts\n",
    "rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "#load boston dataset\n",
    "boston_dataset = datasets.load_boston()\n",
    "boston_data = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s1",
     "l1",
     "hint"
    ]
   },
   "source": [
    "<p>use .head() to list the top rows</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s1",
     "l1",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "boston_sample = boston_data.head(10)\n",
    "boston_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s1",
     "hid",
     "l1"
    ]
   },
   "outputs": [],
   "source": [
    "ref_tmp_var = False\n",
    "\n",
    "\n",
    "try:\n",
    "    ref_assert_var = False\n",
    "    from pandas.util.testing import assert_frame_equal\n",
    "    \n",
    "    boston_sample_ = boston_data.head(10)\n",
    "    \n",
    "    try:\n",
    "        assert_frame_equal(boston_sample_, boston_sample)\n",
    "        ref_assert_var = True\n",
    "        out = boston_sample.head(10)\n",
    "    except:\n",
    "        ref_assert_var = False\n",
    "    \n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        ref_tmp_var = True\n",
    "    else:\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "\n",
    "\n",
    "assert ref_tmp_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l2",
     "content",
     "s2"
    ]
   },
   "source": [
    "<br/><br/><br/><br/>\n",
    "\n",
    "# Boston Housing Dataset - EDA\n",
    "\n",
    "The data and target are present as properties in boston data. Statsmodels is a library used popularly for linear regression. Boston data is present as independent variables in data and the housing rate as MEDV in target property. Also feature names are listed in feature_names. The desription is available in UCI Machine Learning repository website. \n",
    "\n",
    "<br/><center>Boston Housing Dataset</center>\n",
    "\n",
    "| CRIM  | per capita crime rate by town                                         |\n",
    "|-------|-----------------------------------------------------------------------|\n",
    "| ZN    | proportion of residential land zoned for lots over 25,000 sq.ft.      |\n",
    "| INDUS | proportionof non-retail business acres per town                       |\n",
    "| CHAS  | Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) |\n",
    "\n",
    "\n",
    "The task is to model the median value of owner-occupied homes given all the factors. Some factors could affect the housing value and some may not. \n",
    "\n",
    "<br/>\n",
    "# Scatter Plots or Joint plots using seaborn\n",
    "\n",
    "To visualize how each factor would affect housing rate, we can run a scatter plot of the housing rate for each dependent variable. This will help visualize how the target vector may be affected by each factor. Later we shall study quantitave methods that can provide us methods to measure how each factor affects the output or if it doesnt affect the output at all.\n",
    "\n",
    "g = sns.jointplot(\"MEDV\", \"CRIM\", data=df, xlim=(0, 60), ylim=(0, 12), color=\"r\", size=7)\n",
    "\n",
    "<img src='https://s3.amazonaws.com/rfjh/media/CKEditorImages/2016/11/25/figure_1_Ctunq42.png'></img>\n",
    "\n",
    "From the above plot we can observe that the median value of the houses in Boston peaks at lowest crime rates which makes logical sense. This is one of the goals of EDA; to discover patterns in scatter plots and make sense of the input variables. The input variables are also called indepedent variables since they affect the value of the target variable, which is called the dependent variable.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Generate a joint plot of Boston house prices vs Lower status of the population and assign the plot to variable g as shown in the demo code below.\n",
    "- What is your interpretation of the scatter plot?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l2",
     "ce",
     "s2"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "boston_data['MEDV'] = boston_dataset.target\n",
    "\n",
    "# Modify this to plot MEDV vs Lower status of the population.\n",
    "g = sns.jointplot(\"MEDV\", \"CRIM\", data=boston_data, xlim=(0, 60), ylim=(0, 12), color=\"r\", size=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l2",
     "s2",
     "hint"
    ]
   },
   "source": [
    "<p>Look up the symbol for Lower status of the population.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l2",
     "s2",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "g = sns.jointplot(\"MEDV\", \"LSTAT\", data=boston_data, xlim=(0, 60), ylim=(0, 12), color=\"r\", size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l2",
     "hid",
     "s2"
    ]
   },
   "outputs": [],
   "source": [
    "ref_tmp_var = False\n",
    "\n",
    "\n",
    "try:\n",
    "    ref_assert_var = False\n",
    "    g_ = sns.jointplot(\"MEDV\", \"LSTAT\", data=boston_data, xlim=(0, 60), ylim=(0, 12), color=\"r\", size=7)\n",
    "    comp_array = [g.y == g_.y]\n",
    "    \n",
    "    if np.any(comp_array[0] == False) == False:\n",
    "      ref_assert_var = True\n",
    "      out = sns.plt\n",
    "    else:\n",
    "      ref_assert_var = False\n",
    "    \n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        ref_tmp_var = True\n",
    "    else:\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "\n",
    "\n",
    "assert ref_tmp_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l3",
     "s3",
     "content"
    ]
   },
   "source": [
    "<br/><br/><br/><br/><br/>\n",
    "\n",
    "\n",
    "\n",
    "## Categorical Variables\n",
    "\n",
    "We can now look at scatter plots of all input variables with seaborn:\n",
    "\n",
    "<img src='https://s3.amazonaws.com/rfjh/media/CKEditorImages/2016/11/25/figure_2.png'/>\n",
    "\n",
    "The above is helpful to visualize what factors might be significant. However, there are quantitative tests that we shall learn to verify our assumptions. \n",
    "\n",
    "\n",
    "# Categorical Variables \n",
    "\n",
    "In Fig. 2 the feature CHAS only takes two values 0.0 and 1.0. It is essentialy a boolean value as described in the table as well. Note that when descriptions are not available, we can still look at unique value of a feature or plot graphs to discover such occurences. This feature indicates Charles river proximity in a certain manner. Such variables that take boolean values or variables such as day of the week which can take a range of unique values are called as categorical variables. There are better plots to visualize such variables. While selecting categorical variables it is important that the fraction of unique values is relatively small compared to the total dataset. To visualize the categorical data, we can use stripplot:\n",
    "\n",
    "```python\n",
    "sns.stripplot(x=\"CHAS\", y=\"MEDV\", data=boston_data);\n",
    "With seaborn, you can adjust the plots with the settings buttons at the bottom.\n",
    "```\n",
    "\n",
    "<img src='https://s3.amazonaws.com/rfjh/media/CKEditorImages/2016/11/25/figure_3.png'/>\n",
    "\n",
    "\n",
    "The joint plots and scatter plots by default overlap the points and therefore to visualize density becomes a tough task, esp when such overlapping points are high in the map. To resolve this issue, you can set the flag called jitter to True which spreads high density of overlapping points. \n",
    "\n",
    "\n",
    "<img src='https://s3.amazonaws.com/rfjh/media/CKEditorImages/2016/11/25/figure_4.png'/>\n",
    " \n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "To identify categorical variables, you can study the scatter plots to see a fixed set of limited values or can look up the unique values in the feature with the command:\n",
    "\n",
    "```python\n",
    "boston_data['CHAS'].unique()\n",
    "array([ 0.,  1.])\n",
    "```\n",
    "\n",
    "- Identify the other categorical variable in the dataset and generate a stripplot against MEDV setting jitter to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l3",
     "s3",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l3",
     "s3",
     "hint"
    ]
   },
   "source": [
    "<p>Lookup the graph and print out the array of all the unique values. If the values are limited and much lesser than the total dataset size then it is a categorical variable. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l3",
     "s3",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "boston_data['RAD'].unique()\n",
    "g = sns.stripplot(x=\"RAD\", y=\"MEDV\", data=boston_data, jitter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l3",
     "s3",
     "hid"
    ]
   },
   "outputs": [],
   "source": [
    "ref_tmp_var = False\n",
    "\n",
    "\n",
    "try:\n",
    "    ref_assert_var = False\n",
    "    xlabel_ = g.get_xlabel()\n",
    "    \n",
    "    if xlabel_ == 'RAD':\n",
    "      ref_assert_var = True\n",
    "      out = sns.plt\n",
    "    else:\n",
    "      ref_assert_var = False\n",
    "    \n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        ref_tmp_var = True\n",
    "    else:\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "\n",
    "\n",
    "assert ref_tmp_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l4",
     "s4",
     "content"
    ]
   },
   "source": [
    "<br/><br/><br/>\n",
    "# Regression Using Statsmodels\n",
    "\n",
    "Statsmodels is a library used widely for linear regression. The linear regression library has convenient ways to specify parameters for regression and hence is popularly used. The format to specify regression for a single variable is:\n",
    "\n",
    "```python\n",
    "lm = sm.ols(formula = 'y ~ x')\n",
    "```\n",
    "where x is a dependent variable. Let us look at how housing rate is affected by crime rate. \n",
    "\n",
    "```python\n",
    "lm = sm.ols(formula='MEDV ~ CRIM', data=boston_data).fit()\n",
    "```\n",
    "This is called simple regression as only one variable affects the target variable. The above command trains the model lm with input as CRIM and target as MEDV. If many variables are involved in modeling the target, then it is called multiple linear regression. \n",
    "\n",
    "To get prediction from the trained model:\n",
    "\n",
    "```python\n",
    "y_hat = lm.predict(boston_data[['CRIM']])\n",
    "```\n",
    "<br/>\n",
    "\n",
    "## Parameters of Linear Regression\n",
    "\n",
    "The main parameters of linear regression are the intecept and the coefficients. Print out the main parameters with the command:\n",
    "\n",
    "lm.params\n",
    "\n",
    "Intercept    24.016220\n",
    "CRIM         -0.412775\n",
    "dtype: float64\n",
    "\n",
    "The coeffecient of CRIM shows the value by which housing rate changes for every unit increase in crime rate. Since it is negative, we can interpret that for every unit incrase in crime rate, the housing rate declines by -0.412775. \n",
    "\n",
    "The most important parameter to look for is the mean squared error, which tells us how good the predictions matched the ground truth or the target variable.\n",
    "\n",
    "```python\n",
    "print(\"MSE:\", mean_squared_error(boston_data['MEDV'].values, y_hat))\n",
    "MSE: 71.8523466653\n",
    "```\n",
    "<br/>\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Build a model of Housing price for input as average number of rooms per dwelling.\n",
    "- Run prediction on the trained model. Assign the predictions to y_hat.\n",
    "- What is the MSE? Assign the mean squared error to mse_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l4",
     "s4",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Modify this to incorporate average number of rooms per dwelling as an input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s4",
     "l4",
     "hint"
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s4",
     "l4",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "lm = sm.ols(formula='MEDV ~ RM', data=boston_data).fit()\n",
    "y_hat = lm.predict(boston_data[['RM']])\n",
    "mse_lm = mean_squared_error(y_hat, boston_data[['RM']])\n",
    "print(\"MSE:\", mean_squared_error(y_hat, boston_data[['MEDV']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s4",
     "hid",
     "l4"
    ]
   },
   "outputs": [],
   "source": [
    "ref_tmp_var = False\n",
    "\n",
    "\n",
    "try:\n",
    "    ref_assert_var = False\n",
    "    lm_ = sm.ols(formula='MEDV ~ RM', data=boston_data).fit()\n",
    "    y_hat_ = lm_.predict(boston_data[['RM']])\n",
    "    mse_lm_ = mean_squared_error(y_hat_, boston_data[['RM']])\n",
    "    \n",
    "    comp_ = [y_hat == y_hat_]\n",
    "    \n",
    "    ref_assert_var = True\n",
    "    for i in comp_[0]:\n",
    "      if i == False:\n",
    "        ref_assert_var = False\n",
    "    \n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        ref_tmp_var = True\n",
    "    else:\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "\n",
    "\n",
    "assert ref_tmp_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l5",
     "content",
     "s5"
    ]
   },
   "source": [
    "\n",
    "<br/><br/><br/>\n",
    "# Improving the Fit - R-squared & Feature Engineering\n",
    "\n",
    "'Improving the fit' or 'Fine tuning the model' are popular terms amongst data scientists. These terms refer to manipulating various parameters of linear regression model inputs as well as certain practices that enhance the predictions. We shall now study various such steps that are involved in improving the fit, thereby reducing the MSE.\n",
    "\n",
    "There are other output parameters of linear regression that can be seen with the command:\n",
    "\n",
    "lm.summary()\n",
    "<div style='margin-top: -80px;'>\n",
    "<table class=\"simpletable\" style='float: left;'>\n",
    "<caption>OLS Regression Results</caption>\n",
    "<tbody><tr>\n",
    "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared:         </th> <td>   0.484</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.483</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   471.8</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Date:</th>             <td>Fri, 09 Jun 2017</td> <th>  Prob (F-statistic):</th> <td>2.49e-74</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Time:</th>                 <td>01:26:36</td>     <th>  Log-Likelihood:    </th> <td> -1673.1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3350.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Df Residuals:</th>          <td>   504</td>      <th>  BIC:               </th> <td>   3359.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
    "</tr>\n",
    "</tbody></table>\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "<table class=\"simpletable\" style='float: left;'>\n",
    "<tbody><tr>\n",
    "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Intercept</th> <td>  -34.6706</td> <td>    2.650</td> <td>  -13.084</td> <td> 0.000</td> <td>  -39.877</td> <td>  -29.465</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>RM</th>        <td>    9.1021</td> <td>    0.419</td> <td>   21.722</td> <td> 0.000</td> <td>    8.279</td> <td>    9.925</td>\n",
    "</tr>\n",
    "</tbody></table>\n",
    "<br/><br/><br/><br/><br/>\n",
    "<table class=\"simpletable\" style='float: left;'>\n",
    "<tbody><tr>\n",
    "  <th>Omnibus:</th>       <td>102.585</td> <th>  Durbin-Watson:     </th> <td>   0.684</td> \n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 612.449</td> \n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Skew:</th>          <td> 0.726</td>  <th>  Prob(JB):          </th> <td>1.02e-133</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Kurtosis:</th>      <td> 8.190</td>  <th>  Cond. No.          </th> <td>    58.4</td> \n",
    "</tr>\n",
    "</tbody></table>\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "</div>\n",
    "Amongst the various parameters in the above summary, the interesting ones we should study are R-squared and the coefficients. \n",
    "\n",
    "<br/>\n",
    "## R-squared:\n",
    "\n",
    "R-squared is a value between 0 and 1.0 to measure how well the dependent variables are effectively modeling the target variable. The higher the value, the better that the dependent variables explain the fit. Here we see that the R-squared is a low value closer to 0.0 which shows that the crime rate alone is not a good indicator of the housing rate. To increase the R-squared value and get better fit or predictions, the best way is to increase the number of independent variables (also called Feature Engineering)\n",
    "\n",
    "<br/>\n",
    "### Instructions\n",
    "Consider another variable, RM to fit the regression model.\n",
    "\n",
    "- What is the new R-squared? Assign R-squared to a variable r_squared and print it out.\n",
    "- What is the value of MSE? Assign MSE to mse_lm and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l5",
     "ce",
     "s5"
    ]
   },
   "outputs": [],
   "source": [
    "# Modify the code below to add RM to the regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l5",
     "s5",
     "hint"
    ]
   },
   "source": [
    "<p>The method to add dependent variables is to use + sign. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l5",
     "s5",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "lm = sm.ols(formula = 'MEDV ~ CRIM + RM', data=boston_data).fit()\n",
    "y_hat = lm.predict(boston_data[['CRIM', 'RM']])\n",
    "mse_lm = mean_squared_error(boston_data['MEDV'].values, y_hat)\n",
    "r_squared = lm.rsquared\n",
    "print(\"MSE:\", mse_lm, \"R-Squared: \", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "hid",
     "l5",
     "s5"
    ]
   },
   "outputs": [],
   "source": [
    "ref_tmp_var = False\n",
    "\n",
    "\n",
    "try:\n",
    "    ref_assert_var = False\n",
    "    lm_ = sm.ols(formula = 'MEDV ~ CRIM + RM', data=boston_data).fit()\n",
    "    y_hat_ = lm_.predict(boston_data[['CRIM', 'RM']])\n",
    "    mse_lm_ = mean_squared_error(boston_data['MEDV'].values, y_hat_)\n",
    "    r_squared_ = lm_.rsquared\n",
    "    \n",
    "    if (abs(r_squared_ - r_squared) < 0.001) and (abs(mse_lm - mse_lm_) < 0.001):\n",
    "      ref_assert_var = True\n",
    "    else:\n",
    "      ref_assert_var = False\n",
    "    \n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        ref_tmp_var = True\n",
    "    else:\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "\n",
    "\n",
    "assert ref_tmp_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "content",
     "l6",
     "s6"
    ]
   },
   "source": [
    "\n",
    "<br/><br/><br/>\n",
    "# Improving the fit - P-values\n",
    "We saw previously that R-squared increased to 0.541(closer to 1.0 than previous value) which shows that the two variables together can model the house prices in Boston much better than just one variable, CRIM. Hence, we can choose to add all the variables to improve the fit:\n",
    "\n",
    "Including all the variables, \n",
    "\n",
    "```python\n",
    "lm = sm.ols(formula = 'MEDV ~ CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD +     \n",
    "                       TAX + PTRATIO + B + LSTAT', data=boston_data).fit()\n",
    "```\n",
    "\n",
    "Predicting over the features:\n",
    "\n",
    "\n",
    "```python\n",
    "y_hat = lm.predict(boston_data[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM',\n",
    "                                'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B',\n",
    "                                'LSTAT']])\n",
    "print(\"MSE:\", mean_squared_error(boston_data['MEDV'].values, y_hat))      \n",
    "MSE: 21.8977792177\n",
    "```\n",
    "\n",
    "Note that the + sign between the input features in the above commands doesn't mean the variable are added but rather is used as a separator to specify various input features that are used in the modeling. The Mean Squared Error (MSE) reduced considerably which shows that the fit was better.\n",
    "\n",
    "lm.summary()\n",
    "<div style='margin-top: -70px'>\n",
    "<table class=\"simpletable\" style='float: left'>\n",
    "<caption>OLS Regression Results</caption>\n",
    "<tbody><tr>\n",
    "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared:         </th> <td>   0.541</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.539</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   295.9</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Date:</th>             <td>Fri, 09 Jun 2017</td> <th>  Prob (F-statistic):</th> <td>1.15e-85</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Time:</th>                 <td>01:38:17</td>     <th>  Log-Likelihood:    </th> <td> -1643.5</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3293.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Df Residuals:</th>          <td>   503</td>      <th>  BIC:               </th> <td>   3306.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
    "</tr>\n",
    "</tbody></table>\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "<table class=\"simpletable\" style='float: left'>\n",
    "<tbody><tr>\n",
    "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Intercept</th> <td>  -29.3017</td> <td>    2.592</td> <td>  -11.303</td> <td> 0.000</td> <td>  -34.395</td> <td>  -24.208</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>CRIM</th>      <td>   -0.2618</td> <td>    0.033</td> <td>   -7.899</td> <td> 0.000</td> <td>   -0.327</td> <td>   -0.197</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>RM</th>        <td>    8.3975</td> <td>    0.406</td> <td>   20.706</td> <td> 0.000</td> <td>    7.601</td> <td>    9.194</td>\n",
    "</tr>\n",
    "</tbody></table>\n",
    "<br/><br/><br/><br/><br/><br/><br/>\n",
    "<table class=\"simpletable\" style='float: left'>\n",
    "<tbody><tr>\n",
    "  <th>Omnibus:</th>       <td>170.471</td> <th>  Durbin-Watson:     </th> <td>   0.805</td> \n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1034.461</td> \n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Skew:</th>          <td> 1.331</td>  <th>  Prob(JB):          </th> <td>2.34e-225</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>Kurtosis:</th>      <td> 9.479</td>  <th>  Cond. No.          </th> <td>    92.2</td> \n",
    "</tr>\n",
    "</tbody></table>\n",
    "</div>\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "The R-squared increased to 0.741 showing that including all the variables better fits the linear regression model and produces better results.\n",
    "\n",
    "\n",
    "<br/>\n",
    "## P-Values\n",
    "p-values for each variable is an indicator of the significance of the latter in the modeling. Variables with p-values > 0.05 are considered insignificant. Such variables can be dropped from modeling the target variable.\n",
    "\n",
    "\n",
    "<br/>\n",
    "### Instructions\n",
    "Looking at the summary of the model trained with all parameters below. Run the insignifiant variable and run regression again.\n",
    "\n",
    "<img src='https://s3.amazonaws.com/rfjh/media/CKEditorImages/2017/03/22/Screen_Shot_2017-03-22_at_4.01.06_PM.png'/>\n",
    "\n",
    "- Drop these variables from the fit and determine\n",
    "  - MSE - Assign to variable mse_lm\n",
    "  - R-squared - Assign to variable r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "tags": [
     "ce",
     "l6",
     "s6"
    ]
   },
   "outputs": [],
   "source": [
    "lm = sm.ols(formula = 'MEDV ~ CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT', data=boston_data).fit()\n",
    "y_hat = lm.predict(boston_data[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']])\n",
    "print(\"MSE:\", mean_squared_error(boston_data['MEDV'].values, y_hat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l6",
     "s6",
     "hint"
    ]
   },
   "source": [
    "<p>Drop variables whose p-values are greater than 0.05</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l6",
     "s6",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "lm = sm.ols(formula = 'MEDV ~ CRIM + ZN + CHAS + NOX + RM + DIS + RAD + TAX + PTRATIO + B + LSTAT', data=boston_data).fit()\n",
    "y_hat = lm.predict(boston_data[['CRIM', 'ZN', 'CHAS', 'NOX', 'RM', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']])\n",
    "mse_lm = mean_squared_error(boston_data['MEDV'].values, y_hat)\n",
    "r_squared = lm.rsquared\n",
    "print(\"MSE:\", mse_lm, r_squared)\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "hid",
     "s6",
     "l6"
    ]
   },
   "outputs": [],
   "source": [
    "ref_tmp_var = False\n",
    "\n",
    "\n",
    "try:\n",
    "    ref_assert_var = False\n",
    "    lm_ = sm.ols(formula = 'MEDV ~ CRIM + ZN + CHAS + NOX + RM + DIS + RAD + TAX + PTRATIO + B +                LSTAT', data=boston_data).fit()\n",
    "    y_hat_ = lm_.predict(boston_data[['CRIM', 'ZN', 'CHAS', 'NOX', 'RM', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']])\n",
    "    mse_lm_ = mean_squared_error(boston_data['MEDV'].values, y_hat_)\n",
    "    r_squared_ = lm_.rsquared\n",
    "    \n",
    "    if (abs(mse_lm_ - mse_lm) < 0.001) and (abs(r_squared_ - r_squared) < 0.001):\n",
    "      ref_assert_var = True\n",
    "    else:\n",
    "      ref_assert_var = False\n",
    "    \n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        ref_tmp_var = True\n",
    "    else:\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "\n",
    "\n",
    "assert ref_tmp_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l7",
     "s7",
     "content"
    ]
   },
   "source": [
    "\n",
    "<br/><br/><br/>\n",
    "# Improving the fit - Multicollinearity\n",
    "Many times, more than one input could be dependent on each other. In Linear Regression, the requirement is that all the input variables are independent of each other. When a feature is dependent on one or more of the other input features, it leads to a phenomenon known as multi-collinearity or correlation. This can be visualized by a heat map which shows the correlation between all the features. In the housing data, the heat map can be visualized by first calculating the correlation value.\n",
    "\n",
    "```python\n",
    "correlations = boston_data[features].corr()\n",
    "correlations\n",
    "```\n",
    "\n",
    "This displays the matrix of correlation values. Values closer to 1.0 show high correlation between the features and those closer to 0.0 otherwise.\n",
    "\n",
    "<div style='margin-top: 40px;'>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>CRIM</th>\n",
    "      <th>ZN</th>\n",
    "      <th>INDUS</th>\n",
    "      <th>CHAS</th>\n",
    "      <th>NOX</th>\n",
    "      <th>RM</th>\n",
    "      <th>AGE</th>\n",
    "      <th>DIS</th>\n",
    "      <th>RAD</th>\n",
    "      <th>TAX</th>\n",
    "      <th>PTRATIO</th>\n",
    "      <th>B</th>\n",
    "      <th>LSTAT</th>\n",
    "      <th>MEDV</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>CRIM</th>\n",
    "      <td>1.000000</td>\n",
    "      <td>-0.199458</td>\n",
    "      <td>0.404471</td>\n",
    "      <td>-0.055295</td>\n",
    "      <td>0.417521</td>\n",
    "      <td>-0.219940</td>\n",
    "      <td>0.350784</td>\n",
    "      <td>-0.377904</td>\n",
    "      <td>0.622029</td>\n",
    "      <td>0.579564</td>\n",
    "      <td>0.288250</td>\n",
    "      <td>-0.377365</td>\n",
    "      <td>0.452220</td>\n",
    "      <td>-0.385832</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>ZN</th>\n",
    "      <td>-0.199458</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>-0.533828</td>\n",
    "      <td>-0.042697</td>\n",
    "      <td>-0.516604</td>\n",
    "      <td>0.311991</td>\n",
    "      <td>-0.569537</td>\n",
    "      <td>0.664408</td>\n",
    "      <td>-0.311948</td>\n",
    "      <td>-0.314563</td>\n",
    "      <td>-0.391679</td>\n",
    "      <td>0.175520</td>\n",
    "      <td>-0.412995</td>\n",
    "      <td>0.360445</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>INDUS</th>\n",
    "      <td>0.404471</td>\n",
    "      <td>-0.533828</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>0.062938</td>\n",
    "      <td>0.763651</td>\n",
    "      <td>-0.391676</td>\n",
    "      <td>0.644779</td>\n",
    "      <td>-0.708027</td>\n",
    "      <td>0.595129</td>\n",
    "      <td>0.720760</td>\n",
    "      <td>0.383248</td>\n",
    "      <td>-0.356977</td>\n",
    "      <td>0.603800</td>\n",
    "      <td>-0.483725</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>CHAS</th>\n",
    "      <td>-0.055295</td>\n",
    "      <td>-0.042697</td>\n",
    "      <td>0.062938</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>0.091203</td>\n",
    "      <td>0.091251</td>\n",
    "      <td>0.086518</td>\n",
    "      <td>-0.099176</td>\n",
    "      <td>-0.007368</td>\n",
    "      <td>-0.035587</td>\n",
    "      <td>-0.121515</td>\n",
    "      <td>0.048788</td>\n",
    "      <td>-0.053929</td>\n",
    "      <td>0.175260</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>NOX</th>\n",
    "      <td>0.417521</td>\n",
    "      <td>-0.516604</td>\n",
    "      <td>0.763651</td>\n",
    "      <td>0.091203</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>-0.302188</td>\n",
    "      <td>0.731470</td>\n",
    "      <td>-0.769230</td>\n",
    "      <td>0.611441</td>\n",
    "      <td>0.668023</td>\n",
    "      <td>0.188933</td>\n",
    "      <td>-0.380051</td>\n",
    "      <td>0.590879</td>\n",
    "      <td>-0.427321</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>RM</th>\n",
    "      <td>-0.219940</td>\n",
    "      <td>0.311991</td>\n",
    "      <td>-0.391676</td>\n",
    "      <td>0.091251</td>\n",
    "      <td>-0.302188</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>-0.240265</td>\n",
    "      <td>0.205246</td>\n",
    "      <td>-0.209847</td>\n",
    "      <td>-0.292048</td>\n",
    "      <td>-0.355501</td>\n",
    "      <td>0.128069</td>\n",
    "      <td>-0.613808</td>\n",
    "      <td>0.695360</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>AGE</th>\n",
    "      <td>0.350784</td>\n",
    "      <td>-0.569537</td>\n",
    "      <td>0.644779</td>\n",
    "      <td>0.086518</td>\n",
    "      <td>0.731470</td>\n",
    "      <td>-0.240265</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>-0.747881</td>\n",
    "      <td>0.456022</td>\n",
    "      <td>0.506456</td>\n",
    "      <td>0.261515</td>\n",
    "      <td>-0.273534</td>\n",
    "      <td>0.602339</td>\n",
    "      <td>-0.376955</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>DIS</th>\n",
    "      <td>-0.377904</td>\n",
    "      <td>0.664408</td>\n",
    "      <td>-0.708027</td>\n",
    "      <td>-0.099176</td>\n",
    "      <td>-0.769230</td>\n",
    "      <td>0.205246</td>\n",
    "      <td>-0.747881</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>-0.494588</td>\n",
    "      <td>-0.534432</td>\n",
    "      <td>-0.232471</td>\n",
    "      <td>0.291512</td>\n",
    "      <td>-0.496996</td>\n",
    "      <td>0.249929</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>RAD</th>\n",
    "      <td>0.622029</td>\n",
    "      <td>-0.311948</td>\n",
    "      <td>0.595129</td>\n",
    "      <td>-0.007368</td>\n",
    "      <td>0.611441</td>\n",
    "      <td>-0.209847</td>\n",
    "      <td>0.456022</td>\n",
    "      <td>-0.494588</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>0.910228</td>\n",
    "      <td>0.464741</td>\n",
    "      <td>-0.444413</td>\n",
    "      <td>0.488676</td>\n",
    "      <td>-0.381626</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>TAX</th>\n",
    "      <td>0.579564</td>\n",
    "      <td>-0.314563</td>\n",
    "      <td>0.720760</td>\n",
    "      <td>-0.035587</td>\n",
    "      <td>0.668023</td>\n",
    "      <td>-0.292048</td>\n",
    "      <td>0.506456</td>\n",
    "      <td>-0.534432</td>\n",
    "      <td>0.910228</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>0.460853</td>\n",
    "      <td>-0.441808</td>\n",
    "      <td>0.543993</td>\n",
    "      <td>-0.468536</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>PTRATIO</th>\n",
    "      <td>0.288250</td>\n",
    "      <td>-0.391679</td>\n",
    "      <td>0.383248</td>\n",
    "      <td>-0.121515</td>\n",
    "      <td>0.188933</td>\n",
    "      <td>-0.355501</td>\n",
    "      <td>0.261515</td>\n",
    "      <td>-0.232471</td>\n",
    "      <td>0.464741</td>\n",
    "      <td>0.460853</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>-0.177383</td>\n",
    "      <td>0.374044</td>\n",
    "      <td>-0.507787</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>B</th>\n",
    "      <td>-0.377365</td>\n",
    "      <td>0.175520</td>\n",
    "      <td>-0.356977</td>\n",
    "      <td>0.048788</td>\n",
    "      <td>-0.380051</td>\n",
    "      <td>0.128069</td>\n",
    "      <td>-0.273534</td>\n",
    "      <td>0.291512</td>\n",
    "      <td>-0.444413</td>\n",
    "      <td>-0.441808</td>\n",
    "      <td>-0.177383</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>-0.366087</td>\n",
    "      <td>0.333461</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>LSTAT</th>\n",
    "      <td>0.452220</td>\n",
    "      <td>-0.412995</td>\n",
    "      <td>0.603800</td>\n",
    "      <td>-0.053929</td>\n",
    "      <td>0.590879</td>\n",
    "      <td>-0.613808</td>\n",
    "      <td>0.602339</td>\n",
    "      <td>-0.496996</td>\n",
    "      <td>0.488676</td>\n",
    "      <td>0.543993</td>\n",
    "      <td>0.374044</td>\n",
    "      <td>-0.366087</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>-0.737663</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>MEDV</th>\n",
    "      <td>-0.385832</td>\n",
    "      <td>0.360445</td>\n",
    "      <td>-0.483725</td>\n",
    "      <td>0.175260</td>\n",
    "      <td>-0.427321</td>\n",
    "      <td>0.695360</td>\n",
    "      <td>-0.376955</td>\n",
    "      <td>0.249929</td>\n",
    "      <td>-0.381626</td>\n",
    "      <td>-0.468536</td>\n",
    "      <td>-0.507787</td>\n",
    "      <td>0.333461</td>\n",
    "      <td>-0.737663</td>\n",
    "      <td>1.000000</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "The heat map can be displayed with the command:\n",
    "```python\n",
    "sns.heatmap(boston_data, annot=True, fmt=\"d\", linewidths=.5)\n",
    "```\n",
    "\n",
    "\n",
    "<img src='https://s3.amazonaws.com/rfjh/media/CKEditorImages/2016/11/26/figure_9.png'/>\n",
    "From the above map, we can see that the correlation between RAD and TAX is 0.91 which is high.\n",
    "\n",
    "\n",
    "<br/>\n",
    "### Instructions\n",
    "\n",
    "One of the ways to handle multi-collinearity is to keep one of the correlated variables and remove the rest from the modeling.\n",
    "\n",
    "- Remove TAX as it is correlated with RAD and\n",
    "- Use statsmodels package to model the target variable, MEDV.\n",
    "- What is the MSE? Assign it to a variable mse_lm and print the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l7",
     "s7",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "lm = sm.ols(formula = 'MEDV ~ CRIM + ZN + CHAS + NOX + RM + DIS + RAD + TAX + PTRATIO + B + LSTAT', data=boston_data).fit()\n",
    "y_hat = lm.predict(boston_data[['CRIM', 'ZN', 'CHAS', 'NOX', 'RM', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']])\n",
    "print(\"MSE:\", mean_squared_error(boston_data['MEDV'].values, y_hat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l7",
     "s7",
     "hint"
    ]
   },
   "source": [
    "<p>Remove TAX from the code.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l7",
     "s7",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "lm = sm.ols(formula = 'MEDV ~ CRIM + ZN + CHAS + NOX + RM + DIS + RAD + PTRATIO + B + LSTAT', data=boston_data).fit()\n",
    "y_hat = lm.predict(boston_data[['CRIM', 'ZN', 'CHAS', 'NOX', 'RM', 'DIS', 'RAD', 'PTRATIO', 'B', 'LSTAT']])\n",
    "mse_lm = mean_squared_error(boston_data['MEDV'].values, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l7",
     "hid",
     "s7"
    ]
   },
   "outputs": [],
   "source": [
    "ref_tmp_var = False\n",
    "\n",
    "\n",
    "try:\n",
    "    ref_assert_var = False\n",
    "    mse_lm_ = mean_squared_error(boston_data['MEDV'].values, y_hat)\n",
    "    \n",
    "    if abs(mse_lm - 22.4425546657) < 0.001:\n",
    "      ref_assert_var = True\n",
    "    else:\n",
    "      ref_assert_var = False\n",
    "    \n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        ref_tmp_var = True\n",
    "    else:\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "\n",
    "\n",
    "assert ref_tmp_var"
   ]
  }
 ],
 "metadata": {
  "executed_sections": [],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "rf_version": 1
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
