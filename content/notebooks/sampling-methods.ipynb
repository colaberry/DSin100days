{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s1",
     "content",
     "l1"
    ]
   },
   "source": [
    "# Sampling Methods\n",
    "\n",
    "In large networks, exact inference is often computationally expensive and impractical. Drawing conclusions from information can be uncertain. Sampling helps in approximate inference. We will call the information as 'evidence' and compute probability of 'query' variable which makes up the different conclusions. Computing probability of a query variable (or variables) taking on a value (or set of values) given some evidence is called probabilistic inference. When it is difficult to sample from a probability distribution directly, we use its conditional probabilities. In other words, we can sample a multidimensional probability distribution from its conditional densities.\n",
    "\n",
    "Given a known probability distribution, a sample will be an assignment of values to each variable in the network. We will then use samples to approximately compute posterior probabilities. Consider the grass sprinkler example. Wet grass can be caused by rain or a sprinkler. Suppose we have observed that the grass is wet. Now consider the additional information that it was cloudy. Does this change your beliefs on how the grass became wet? Let us see.\n",
    "\n",
    "The nodes Cloudy, Rain, Sprinkler and WetGrass are boolean True(+) or False(-). \n",
    "\n",
    "We want to sample values for C. The method used for single variable sampling is that we randomly generate number r between (0,1). If r < 0.5, sample = c+ (c=true), else sample = c- (c=false) \n",
    "\n",
    "There are many sampling methods used for approximate inference. We will see four of them here.\n",
    "* Direct\n",
    "* Rejection\n",
    "* Likelihood weighting \n",
    "* Gibbs sampling\n",
    "\n",
    "## Direct Sampling\n",
    "\n",
    "In direct sampling, we generate samples from a network with no evidence. First, we create a topological order of the variables in the Bayes Network and then sample each variable conditioned on the values of its parents. In the grass sprinkler example, see the below steps for generating a sample of (Cloudy,Sprinkler,Rain,WetGrass) or (C,S,R,W).\n",
    "\n",
    "\n",
    "<img src=\"../images/sprinkler.png\" style=\"width: 900px;\">\n",
    "\n",
    "\n",
    "The above sampling process generates samples from the bayes network. We can use the samples to estimate probability of a specific event. An event is defined as the set of values taken by the variables.\n",
    "Pr[C=t,S=f,R=t,W=t] â‰ˆ [# of samples(t,f,t,t)] / [Total # of samples] becomes exact in large size sample.\n",
    "\n",
    "\n",
    "### Bayesian Network using pgmpy\n",
    "\n",
    "Create the network in the above image using pgmpy and verify the probability distribution. Name the model as grass_model. Use the below code for verifying the network.\n",
    "\n",
    "``` python\n",
    "for cpd in grass_model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "s1",
     "ce",
     "l1"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.models import BayesianModel\n",
    "\n",
    "cloudy_cpd = TabularCPD(variable='C',\n",
    "                       variable_card=2,\n",
    "                       values=[[.5, .5]])\n",
    "\n",
    "sprinkler_cpd = TabularCPD(variable='S',\n",
    "                     variable_card=2,\n",
    "                     values=[[.5, .9],\n",
    "                           [.5, .1]],\n",
    "                     evidence=['C'],\n",
    "                     evidence_card=[2])\n",
    "\n",
    "rain_cpd = TabularCPD(variable='R',\n",
    "                     variable_card=2,\n",
    "                     values=[[.8, .2],\n",
    "                           [.2, .8]],\n",
    "                     evidence=['C'],\n",
    "                     evidence_card=[2])\n",
    "\n",
    "wetgrass_cpd = TabularCPD(\n",
    "                variable='W',\n",
    "                variable_card=2,\n",
    "                values=[[1, .1, .1, .01],\n",
    "                        [0, .9, .9, .99]],\n",
    "                evidence=['S', 'R'],\n",
    "                evidence_card=[2, 2])\n",
    "\n",
    "grass_model = BayesianModel()\n",
    "grass_model = BayesianModel([('C', 'S'),\n",
    "                             ('C', 'R'),\n",
    "                             ('S', 'W'),\n",
    "                             ('R', 'W')])\n",
    "grass_model.add_cpds(cloudy_cpd, sprinkler_cpd, rain_cpd, wetgrass_cpd)\n",
    "grass_model.check_model()\n",
    "\n",
    "# Verify network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s1",
     "hint",
     "l1"
    ]
   },
   "source": [
    "Verify the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s1",
     "ans",
     "l1"
    ]
   },
   "outputs": [],
   "source": [
    "for cpd in grass_model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "s1",
     "hid",
     "l1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    a=1\n",
    "    if a == 1:\n",
    "        ref_assert_var = True\n",
    "        print('continue')\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions. ')\n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s2",
     "content",
     "l2"
    ]
   },
   "source": [
    "## Rejection Sampling\n",
    "\n",
    "Suppose we have evidence, say Spinkler=True and we want to estimate Pr[Rain=t|Sprinkler=t]. We do direct sampling as described above and then reject all samples that are inconsistent with evidence. Say we took 100 samples of which 50 samples had S=t and 50 samples had S=f. We would reject the samples with S=f and then estimate probability of Rain=t from remaining samples. This is inefficient because we are rejecting most of our samples.\n",
    "\n",
    "\n",
    "## Likelihood Weighting Sampling\n",
    "\n",
    "In the above scenario, to estimate Pr[Rain=t | Cloudy=f,WetGrass=t], we will fix the evidence, means we will force the cloudy = true and wetgrass = true and generate samples for Sprinkler and Rain. We generate only those samples that agree with the evidence(here C=f and W=t). We will then weigh them according to the likelihood(probability) of evidence.\n",
    "\n",
    "To generate a sample of (C,S,R,W), we will set the evidence at (C=f and W=t) and initial weight w=1.\n",
    "1. C : evidence variable => w = 1 * Pr[C=f] = 0.5\n",
    "2. S : Sample => Pr[S|C=f] = (.5,.5) => true\n",
    "3. R : Sample => Pr[R|C=f] = (.2,.8) => false\n",
    "4. W : evidence variable => w = 0.5 X Pr[W=t|S=t,R=f] = .5 X .9 = .45\n",
    "\n",
    "We have our first sample as [f,t,f,t] with weight .45.\n",
    "\n",
    "The limitation of this sampling method is that it gives poor performance if the evidence variables occur later in the sampling order. If evidence variables do not occur early in the order, they cannot be used to influence the samples which would lead to samples with lower weights.\n",
    "\n",
    "Reference: http://www.cs.cmu.edu/~arielpro/15381f16/slides/781f16-bn.pdf\n",
    "\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Consider Pr[Sprinkler=f|Cloudy=t,WetGrass=f]. Compute the likelihood weight for the sample (C,S,R,W)=(t,f,t,f) and assign to variable w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s2",
     "ce",
     "l2"
    ]
   },
   "outputs": [],
   "source": [
    "# w=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s2",
     "hint",
     "l2"
    ]
   },
   "source": [
    "Follow the steps to calculate the likelihood weight of the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s2",
     "ans",
     "l2"
    ]
   },
   "outputs": [],
   "source": [
    "w=1\n",
    "c=w*.5\n",
    "w=c*.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "s2",
     "hid",
     "l2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if w == .05:\n",
    "        ref_assert_var = True\n",
    "        print('continue')\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions. ')\n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s3",
     "content",
     "l3"
    ]
   },
   "source": [
    "## Generate samples using pgmpy\n",
    "\n",
    "Use the below code to generate direct, rejection and likelihood weighting samples. Notice that likelihood sample also provides the weight of the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "s3",
     "ce",
     "l3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct Sample: \n",
      " [(0, 1, 0, 1) (1, 0, 1, 1)]\n",
      "\n",
      " Rejection Sample: \n",
      "    C  S  R  W\n",
      "0  0  1  1  1\n",
      "1  0  1  0  1\n",
      "2  0  1  0  1\n",
      "\n",
      " Likelihood Weighting Sample: \n",
      " [(1, 0, 1, 1,  0.81) (1, 0, 0, 1,  0.  )]\n"
     ]
    }
   ],
   "source": [
    "# Direct Sample\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "inference = BayesianModelSampling(grass_model)\n",
    "direct = inference.forward_sample(size=2, return_type='recarray')\n",
    "print(\"Direct Sample: \\n\", direct)\n",
    "\n",
    "# Rejection Sample\n",
    "from pgmpy.factors.discrete import State\n",
    "evidence_rej = [State(var='S', state=1)]\n",
    "rejection = inference.rejection_sample(evidence=evidence_rej, size=3, return_type='dataframe')\n",
    "print(\"\\n Rejection Sample: \\n\", rejection)\n",
    "\n",
    "# Likelihood Weighting Sample\n",
    "evidence_wt = [State('S', 0),State('W',1)]\n",
    "likelihood = inference.likelihood_weighted_sample(evidence=evidence_wt, size=2, return_type='recarray')\n",
    "print(\"\\n Likelihood Weighting Sample: \\n\", likelihood)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s3",
     "hint",
     "l3"
    ]
   },
   "source": [
    "Run the given code to see samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s3",
     "ans",
     "l3"
    ]
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s3",
     "hid",
     "l3"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    a=1\n",
    "    if a == 1:\n",
    "        ref_assert_var = True\n",
    "        print('continue')\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions. ')\n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s4",
     "content",
     "l4"
    ]
   },
   "source": [
    "## Markov Chain Monte Carlo (MCMC)\n",
    "\n",
    "\n",
    "Markov process is a process that is capable of being in more than one state, can make transitions among those states, and in which the states available and transition probabilities depend only upon what state the system is currently in. In other words, there is no memory in a Markov process. It is a stochastic process in which future states are independent of past states given the present state. Stochastic process is a consecutive (time component, $t$) set of random quantities defined on some known state(parameter) space $\\Theta$.\n",
    "\n",
    "Monte Carlo is the simulation method used in the MCMC algorithm. Markov Chain Monte Carlo (MCMC) techniques are used for sampling from probability distributions using Markov chain. MCMC methods are used in data modelling for bayesian inference and numerical integration.\n",
    "\n",
    "Markov Blanket of a node is its parents, children and children's parents. We also assume that nodes are conditionally independent of all other nodes given its Markov Blanket.\n",
    "\n",
    "The direct, rejection and likelihood weighting sampling methods generate each new sample from scratch. MCMC, on the other hand generates each sample by making a random change to the previous sample. We will now see the Gibbs sampling method which uses the MCMC algorithm.\n",
    "\n",
    "\n",
    "## Gibbs Sampling\n",
    "\n",
    "Gibbs sampling procedure starts with initializing all the nodes to a random state. Then sample each state condiditional on all other nodes at their previous states. We will need the find the full conditional of each node.\n",
    "1. Initialize $C_0, S_0, R_0, W_0$\n",
    "2. Sample $C_1\\mid S_0,R_0,W_0$\n",
    "3. Sample $S_1\\mid C_1,R_0,W_0$\n",
    "4. Sample $R_1\\mid C_1,S_1,W_0$\n",
    "5. Sample $W_1\\mid C_1,S_!,R_1$ \n",
    "<br>\n",
    "\n",
    "New sample is (C_1,S_1,R_1,W_1).\n",
    "\n",
    "The initial values are typically chosen to be the states with high probability. The steps 2 to 5 are repeated M times and the first B samples are discarded. This is called the burn-in. This is to make our samples closer to the true distribution and less dependent on the starting point. The choice of B is unclear since our samples are not entirely independent and we are unaware of when convergence happens. For high values of M, the value of B does not matter.\n",
    "\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Use the below code to generate gibbs samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "s4",
     "ce",
     "l4"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>S</th>\n",
       "      <th>R</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C  S  R  W\n",
       "0  0  0  1  0\n",
       "1  1  0  0  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pgmpy.sampling import GibbsSampling\n",
    "inferenceG = GibbsSampling(grass_model)\n",
    "inferenceG.sample(size=2, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s4",
     "hint",
     "l4"
    ]
   },
   "source": [
    "Run the given code to see samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s4",
     "ans",
     "l4"
    ]
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s4",
     "hid",
     "l4"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    a=1\n",
    "    if a == 1:\n",
    "        ref_assert_var = True\n",
    "        print('continue')\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions. ')\n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions. ')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "executed_sections": [],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
