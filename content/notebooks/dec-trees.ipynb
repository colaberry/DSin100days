{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s1",
     "content",
     "l1"
    ]
   },
   "source": [
    "# Decision Trees\n",
    "\n",
    "A Decision tree is a computational model that contains a set of if-then-else decisions to classify data. Its similar to program flow diagrams. For example a bank needs to be opened and the bank wants to know whether the economics such as income levels, number of already existing banks, location and other details that can affect the profitability is known. A decision tree helps to make such decisions based on existing data. The decision trees are used for classification and prediction. Let us use the Titanic example to perform classification on who is likely to survive using Decision Trees. This will be a binary classifier but multi-decision classifiers can also be implemented. The advantage of Decision Trees are that they are interpretable.\n",
    "\n",
    "\n",
    "The root node consists of the entire set of data. A segment or branch is formed by a splitting rule on the data above. A node which branches out is called a decision node. Bottom nodes which do not branch out are called leaves. Splitting rules are applied on each branch creating a hierarchy of branches which form the decision tree. Data points are assigned to nodes in a mutually exclusive manner. For each data point, the decision tree provides a unique path to enter the class that is defined by a leaf. So every data point in the dataset can be found in one leaf only. That leaf gives the probability or frequency of occurence.\n",
    "\n",
    "Let us apply the decision tree model on the survival on Titanic.\n",
    "\n",
    "```python\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "```\n",
    "\n",
    "\n",
    "### matplotlib.style.use('ggplot')\n",
    "```python\n",
    "pd.set_option(\"max_r\",10)\n",
    "```\n",
    "\n",
    "\n",
    "## 1. Processed Titanic Data set\n",
    "\n",
    "Earlier, in the course on EDA, we cleaned up the Titanic data set and introduced new columns that are easy to work with for classification and modeling purposes. We have saved those datasets on github. Load the clean dataset from GitHub:\n",
    "```python\n",
    "train_data = pd.read_csv('https://raw.githubusercontent.com/colaberry/data/master/Titanic/train_data.csv')\n",
    "test_data = pd.read_csv('https://raw.githubusercontent.com/colaberry/data/master/Titanic/test_data.csv')\n",
    "```\n",
    "Choose all the features that are available and can be used for decision making on survival.\n",
    "```python\n",
    "features = ['Pclass', 'SibSp', 'Parch', 'Fare', 'C', 'Q', 'S', 'female', 'male', 'Age_Imputed']\n",
    "```\n",
    "Using the train_test_split, we can split the data into training and testing data sets so we can evaluate the data.\n",
    "```python\n",
    "train_sample, test_sample = train_test_split(train_data, test_size=0.3, random_state=1)\n",
    "```\n",
    "\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Using DecisionTreeClassifier(random_state=) that is imported from the tree module, instantiate a Decision Tree, decision_tree.\n",
    "The .fit takes in features and target as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s1",
     "ce",
     "l1"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import metrics,  tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "pd.set_option(\"max_r\",10)\n",
    "\n",
    "train_data = pd.read_csv('https://raw.githubusercontent.com/colaberry/data/master/Titanic/train_data.csv')\n",
    "test_data = pd.read_csv('https://raw.githubusercontent.com/colaberry/data/master/Titanic/test_data.csv')\n",
    "\n",
    "features = ['Pclass', 'SibSp', 'Parch', 'Fare', 'C', 'Q', 'S', 'female', 'male', 'Age_Imputed']\n",
    "\n",
    "train_sample, test_sample = train_test_split(train_data, test_size=0.3, random_state=20052017)\n",
    "\n",
    "# Instantiate a decision tree & fit it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s1",
     "l1",
     "hint"
    ]
   },
   "source": [
    "<p>use .fit(, ) function with features and target.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s1",
     "l1",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "titanic_tree = tree.DecisionTreeClassifier(random_state=2017)\n",
    "titanic_tree.fit(train_sample[features], train_sample['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s1",
     "hid",
     "l1"
    ]
   },
   "outputs": [],
   "source": [
    "ref_tmp_var = False\n",
    "\n",
    "\n",
    "try:\n",
    "    ref_assert_var = False\n",
    "    titanic_tree_ = tree.DecisionTreeClassifier(random_state=2017)\n",
    "    titanic_tree_.fit(train_sample[features], train_sample['Survived'])\n",
    "    \n",
    "    # Hidden Block\n",
    "    titanic_tree_ = tree.DecisionTreeClassifier(random_state=2017)\n",
    "    titanic_tree_.fit(train_sample[features], train_sample['Survived'])\n",
    "    \n",
    "    # Assertion block\n",
    "    ref_assert_var = False\n",
    "    if (titanic_tree.tree_.value==titanic_tree.tree_.value).all():\n",
    "        ref_assert_var = True\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "    # print(ref_assert_var)\n",
    "    \n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        ref_tmp_var = True\n",
    "    else:\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "\n",
    "\n",
    "assert ref_tmp_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l2",
     "content",
     "s2"
    ]
   },
   "source": [
    "\n",
    "<br/><br/><br/>\n",
    "## 2. Predicting Survival on Titanic with Decision Trees\n",
    "\n",
    "Import StringIO, Image and other libraries useful for visualizing the decision tree. \n",
    "\n",
    "```python\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image\n",
    "\n",
    "import pydotplus\n",
    "```\n",
    "\n",
    "Let us define a function that takes in a tree, features and other variables used to display the decision tree. \n",
    "\n",
    "```python\n",
    "def visualize_tree(sktree, features, classes, impurity = False, label = 'all', proportion = True):\n",
    "    dot_data=StringIO()\n",
    "    tree.export_graphviz(sktree\n",
    "                         , feature_names=features\n",
    "                         , class_names=classes\n",
    "                         , filled=True\n",
    "                         , rounded=True\n",
    "                         , impurity = impurity\n",
    "                         , label = label\n",
    "                         , special_characters=True\n",
    "                         , proportion = proportion\n",
    "                         , out_file=dot_data)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    #  graph.write_pdf(\"tree.pdf\") # Save to your current folder\n",
    "    return(Image(graph.create_png()))\n",
    "```    \n",
    "\n",
    "\n",
    "### Visualizing the Tree\n",
    "```python\n",
    "classes = ['Died', 'Survived']\n",
    "visualize_tree(titanic_tree, features, classes)\n",
    "```\n",
    "<img style='float: left;' src='https://s3.amazonaws.com/rfjh/media/decision_trees.png'/>\n",
    "\n",
    "As you can see above the tree is very complex. The reason was that we never specified any depth of the tree and hence the entire training data has been fit with no bounds to the parameters of the decision tree. Each decision tree has a depth that can control the complexity of the modeling. However, note that depth is a parameter that we need to determine for efficient modeling.\n",
    "\n",
    "\n",
    "## Exercise\n",
    "\n",
    "* Pass in the random number using numpy with year 2017 as the seed.\n",
    "* Make a smaller tree that's easier to interpret with depth = 2 and fit the training sample.\n",
    "* Visualize the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l2",
     "ce",
     "s2"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to Visualize the tree\n",
    "def visualize_tree(sktree, features, classes, impurity = False, label = 'all', proportion = True):\n",
    "    dot_data=StringIO()\n",
    "    tree.export_graphviz(sktree\n",
    "                         , feature_names=features\n",
    "                         , class_names=classes\n",
    "                         , filled=True\n",
    "                         , rounded=True\n",
    "                         , impurity = impurity\n",
    "                         , label = label\n",
    "                         , special_characters=True\n",
    "                         , proportion = proportion\n",
    "                         , out_file=dot_data)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    #  graph.write_pdf(\"tree.pdf\") # Save to your current folder\n",
    "    return(Image(graph.create_png()))\n",
    "\n",
    "classes = ['Died', 'Survived']\n",
    "visualize_tree(titanic_tree, features, classes)\n",
    "\n",
    "# Write code to instantiate, fit and visualize the tree.\n",
    "# titanic_s_tree = tree.DecisionTreeClassifier(random_state = <random number>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l2",
     "s2",
     "hint"
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l2",
     "s2",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "titanic_s_tree = tree.DecisionTreeClassifier(random_state = np.random.seed(2017), max_depth = 2)\n",
    "titanic_s_tree.fit(train_sample[features], train_sample['Survived'])\n",
    "visualize_tree(titanic_s_tree, features, classes, proportion = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l2",
     "hid",
     "s2"
    ]
   },
   "outputs": [],
   "source": [
    "ref_tmp_var = False\n",
    "\n",
    "\n",
    "try:\n",
    "    ref_assert_var = False\n",
    "    titanic_s_tree_ = tree.DecisionTreeClassifier(random_state = np.random.seed(2017), max_depth = 2)\n",
    "    titanic_s_tree_.fit(train_sample[features], train_sample['Survived'])\n",
    "    \n",
    "    # Hidden Block\n",
    "    import numpy as np\n",
    "    \n",
    "    titanic_s_tree_ = tree.DecisionTreeClassifier(random_state = np.random.seed(2017), max_depth = 2)\n",
    "    titanic_s_tree_.fit(train_sample[features], train_sample['Survived'])\n",
    "    y_hat_ = titanic_s_tree_.predict(train_sample[features])\n",
    "    y_hat = titanic_s_tree.predict(train_sample[features])\n",
    "    \n",
    "    # Assertion block\n",
    "    ref_assert_var = False\n",
    "    if np.all(y_hat == y_hat_):\n",
    "        ref_assert_var = True\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "    \n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        ref_tmp_var = True\n",
    "    else:\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "\n",
    "\n",
    "assert ref_tmp_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l3",
     "s3",
     "content"
    ]
   },
   "source": [
    "\n",
    "<br/><br/><br/>\n",
    "## 3. Evaluating the Fit\n",
    "\n",
    "Similar to the previous procedure of validating our models in supervised learning, we need to evaluate the accuracy of the decision tree that was fit. This can be done by using .predict() function and the accuracy score can be measured against the target variable:\n",
    "```python\n",
    "y_hat = titanic_s_tree.predict(train_sample[features])\n",
    "metrics.accuracy_score(train_sample['Survived'], y_hat)\n",
    "```\n",
    "\n",
    "\n",
    "## Exercise\n",
    "* Evaluate the performance of the decision tree that you fit, on the test set and assign it to the variable, dt_accuracy\n",
    "* Use metrics.accuracy_score(, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l3",
     "s3",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "# Evaluate the prediction on the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l3",
     "s3",
     "hint"
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l3",
     "s3",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "y_hat = titanic_s_tree.predict(test_sample[features])\n",
    "dt_accuracy = metrics.accuracy_score(test_sample['Survived'], y_hat)\n",
    "print(dt_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l3",
     "s3",
     "hid"
    ]
   },
   "outputs": [],
   "source": [
    "ref_tmp_var = False\n",
    "\n",
    "\n",
    "try:\n",
    "    ref_assert_var = False\n",
    "    y_hat_ = titanic_s_tree.predict(test_sample[features])\n",
    "    dt_accuracy_ = metrics.accuracy_score(test_sample['Survived'], y_hat_)\n",
    "    \n",
    "    # Hidden Block\n",
    "    y_hat_ = titanic_s_tree.predict(test_sample[features])\n",
    "    dt_accuracy_ = metrics.accuracy_score(test_sample['Survived'], y_hat_)\n",
    "    \n",
    "    # Assertion Block\n",
    "    ref_assert_var = False\n",
    "    if abs(dt_accuracy - dt_accuracy_) < 0.1:\n",
    "        ref_assert_var = True\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "    \n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        ref_tmp_var = True\n",
    "    else:\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "\n",
    "\n",
    "assert ref_tmp_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l4",
     "s4",
     "content"
    ]
   },
   "source": [
    "\n",
    "<br/><br/><br/>\n",
    "## 4. ROC and Accuracy Metrics\n",
    "\n",
    "Let us continue to visualize the tree with max_depth = 2:\n",
    "```python\n",
    "titanic_s_tree.fit(train_sample[features], train_sample['Survived'])\n",
    "visualize_tree(titanic_s_tree, features, classes, proportion = True)\n",
    "```\n",
    "\n",
    "<img style='float: left;' src='https://s3.amazonaws.com/rfjh/media/decision_trees2.png'/>\n",
    "\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "### Interpretating the Tree\n",
    "\n",
    "The tree first splits by sex, and then by class & age since it has learned during the training phase that these are the two most important features for determining survival. Passengers who might survive are shown in dark blue boxes. The people who died are shown in the orange box.\n",
    "\n",
    "\n",
    "#### Evaluating Accuracy\n",
    "\n",
    "Calculate accuracy of prediction on the training data.\n",
    "```python\n",
    "y_hat = titanic_s_tree.predict(train_sample[features])\n",
    "metrics.accuracy_score(train_sample['Survived'], y_hat)\n",
    "```\n",
    "\n",
    "Evaluate the performance on the test set which generally is expected to be lower than the training data set.\n",
    "\n",
    "```python\n",
    "y_hat = titanic_s_tree.predict(test_sample[features])\n",
    "metrics.accuracy_score(test_sample['Survived'], y_hat)\n",
    "```\n",
    "\n",
    "Let us look at the confusion matrix with True Positives, True Negatives, False Positives and False negatives using the pandas crosstab function:\n",
    "```python\n",
    "pd.crosstab(test_sample['Survived'], y_hat, rownames=['actual'], colnames=['prediction'])\n",
    "```\n",
    "\n",
    "\n",
    "## Exercise\n",
    "\n",
    "* Use predict_proba function that takes in the dataframe containing the features and assign to it class_probs\n",
    "* Use the roc_auc_score function to predict the AUC score and assign it to the variable roc_score\n",
    "* print out the ROC Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l4",
     "s4",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set using predict_proba\n",
    "\n",
    "# Calculate the AUC metric\n",
    "# Make predictions on the test set using predict_proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s4",
     "l4",
     "hint"
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s4",
     "l4",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set using predict_proba\n",
    "\n",
    "# Calculate the AUC metric\n",
    "# Make predictions on the test set using predict_proba\n",
    "class_probs = titanic_s_tree.predict_proba(test_sample[features])[:, 1]\n",
    "\n",
    "# Calculate the AUC metric\n",
    "roc_score = metrics.roc_auc_score(test_sample['Survived'], class_probs)\n",
    "print(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s4",
     "hid",
     "l4"
    ]
   },
   "outputs": [],
   "source": [
    "ref_tmp_var = False\n",
    "\n",
    "\n",
    "try:\n",
    "    ref_assert_var = False\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Hidden Block\n",
    "    class_probs_ = titanic_s_tree.predict_proba(test_sample[features])[:, 1]\n",
    "    roc_score_ = metrics.roc_auc_score(test_sample['Survived'], class_probs_)\n",
    "    \n",
    "    ref_assert_var = False\n",
    "    # Assertion Block\n",
    "    if (abs(roc_score - roc_score_) < 0.1):\n",
    "        ref_assert_var = True\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "    \n",
    "    \n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        ref_tmp_var = True\n",
    "    else:\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions.')\n",
    "\n",
    "\n",
    "assert ref_tmp_var"
   ]
  }
 ],
 "metadata": {
  "executed_sections": [],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "rf_version": 1
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
