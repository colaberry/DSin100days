{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s1",
     "content",
     "l1"
    ]
   },
   "source": [
    "# Multiclass Logistic Regression\n",
    "\n",
    "## Multiclass using SKlearn's LogisticRegression\n",
    "\n",
    "In the previous sections, we learnt how to use Sklearn's LogisticRegression module and how to fine tune the parameters for 2 class or binary class problem.\n",
    "\n",
    "In this section, we will learn how to use the LogisticRegression for a multiclass problem involving 3 or more classes.\n",
    "\n",
    "According to the sklearn documentation, in the multiclass scenario, the LogisticRegression algorithm uses the one-vs-rest (OvR) scheme if the ‘multi_class’ option is set to ‘ovr’.\n",
    "It uses the cross-entropy loss if the ‘multi_class’ option is set to ‘multinomial’. \n",
    "\n",
    "A multiclass option of ‘multinomial’ is supported only by certain solvers such as the ‘lbfgs’, ‘sag’, ‘saga’ and ‘newton-cg’.\n",
    "\n",
    "Let us try to take the simple example of iris dataset. \n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "iris = pd.read_csv('../../../data/iris.csv', na_values='?').dropna()\n",
    "iris.info()\n",
    "iris.shape\n",
    "\n",
    "lr_iris = LogisticRegression()\n",
    "lr_iris = lr_iris.fit(X, y)\n",
    "y_pred = lr_iris.predict(X)\n",
    "```\n",
    "Measure the performance of the trained model over the training set:\n",
    "```python\n",
    "lr_iris.score(y_pred, train_data['Survived'])\n",
    "0.96\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "## Exercise:\n",
    "\n",
    "Train the model with LogisticRegression.\n",
    "\n",
    "- Train using scikit learn logistic regression module.\n",
    "- Get the prediction on the training set and print out the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "s1",
     "ce",
     "l1"
    ]
   },
   "outputs": [],
   "source": [
    "# Here is the distplot used to generate Age plot. Modify features variable for fare.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets,metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_data = iris.data\n",
    "iris_data = pd.DataFrame(iris_data, columns=iris.feature_names)\n",
    "iris_data['species'] = iris.target \n",
    "iris_data['species'].unique()\n",
    "\n",
    "features = iris.feature_names\n",
    "target = 'species'\n",
    "\n",
    "X = iris_data[features]\n",
    "y = iris_data[target]\n",
    "\n",
    "#write your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution\n",
    "\n",
    "```python\n",
    "\n",
    "lr_iris = LogisticRegression()\n",
    "lr_iris = lr_iris.fit(X, y)\n",
    "y_pred = lr_iris.predict(X)\n",
    "\n",
    "print(metrics.accuracy_score(y_pred,y))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiclass Parameter\n",
    "\n",
    "SKlearn's LogisticRegression class takes a parameter called multiclass to tune the algorithm for multiclass scenario. LogisticRegression uses two approaches for multiclass problem. \n",
    "\n",
    "### 1. One-Vs-Rest (OVR)\n",
    "\n",
    "One-vs.-rest (or one-vs-all, OvA) classifier involves training a single classifier per class, with the samples of that class as positive sample and all other samples as negatives. For OVA, the assumption is that there are $N$ independent classification problems, meaning $N$ classes, and for each class we learn a logistic (probability) model. The key assumption is that each of these problems is independent of the other $N-1$  logistic regression problems. Hence for each sample we either classify this as class $Y_i$  or not. This is repeated for all classes.\n",
    "\n",
    "\n",
    "### 2. Multinomial\n",
    "\n",
    "The alternative to One vs Rest classifier is the multinomial logistic regression classifier. The multinomial classifier does not classifier each class seperately, instead it uses the softmax function to predict if a single data point falls in one of the $N$ classes. Most of the times you may not see a significant difference in the results but one benifit is that you model the entire distribution $P(Y_i = c ) = \\text{SoftMax} \\big( \\beta_1, x_1, \\beta_2, x_2.... \\beta_n, x_n,  \\big)$ rather than the individual distributions  $P(Y_i = c)$. \n",
    "\n",
    "What method should you use? It typically pays to try both and see how well it works on your validation/test set. \n",
    "\n",
    "Let us try to set the appropriate value for multiclass parameter.\n",
    "\n",
    "First let us try OVR approach. This uses liblinear solver.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Set the multiclass to 'ovr' in LogisticRegression model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution\n",
    "\n",
    "```python\n",
    "\n",
    "lr_iris = LogisticRegression(multi_class='ovr')\n",
    "lr_iris = lr_iris.fit(X, y)\n",
    "y_pred = lr_iris.predict(X)\n",
    "\n",
    "print(metrics.accuracy_score(y_pred,y))```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial option\n",
    "\n",
    "Now let us try multinomial approach\n",
    "\n",
    "\n",
    "Let us try to set the appropriate value for multiclass parameter.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Set the multiclass to 'multinomial' and solver as 'newton-cg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution\n",
    "\n",
    "```python\n",
    "\n",
    "lr_iris = LogisticRegression(multi_class='multinomial',solver='newton-cg')\n",
    "lr_iris = lr_iris.fit(X, y)\n",
    "y_pred = lr_iris.predict(X)\n",
    "\n",
    "print(metrics.accuracy_score(y_pred,y))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Solver options - lbfgs\n",
    "\n",
    "Now let us try different solvers for multinomial\n",
    "\n",
    "\n",
    "Let us try  lbfgs as the solver in this case.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Set the multiclass to 'multinomial' and solver as 'lbfgs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution\n",
    "\n",
    "```python\n",
    "lr_iris = LogisticRegression(multi_class='multinomial',solver='lbfgs')\n",
    "lr_iris = lr_iris.fit(X, y)\n",
    "y_pred = lr_iris.predict(X)\n",
    "\n",
    "print(metrics.accuracy_score(y_pred,y))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Solver options - SAG\n",
    "\n",
    "Now let us try different solvers for multinomial\n",
    "\n",
    "\n",
    "Let us try  sag as the solver..\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Set the multiclass to 'multinomial' and solver as 'sag'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution\n",
    "\n",
    "```python\n",
    "lr_iris = LogisticRegression(multi_class='multinomial',solver='sag')\n",
    "lr_iris = lr_iris.fit(X, y)\n",
    "y_pred = lr_iris.predict(X)\n",
    "\n",
    "print(metrics.accuracy_score(y_pred,y))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Solver options - SAGA\n",
    "\n",
    "Now let us try different solvers for multinomial\n",
    "\n",
    "\n",
    "Let us try  saga as the solver.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Set the multiclass to 'multinomial' and solver as 'saga'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution\n",
    "\n",
    "```python\n",
    "lr_iris = LogisticRegression(multi_class='multinomial',solver='saga')\n",
    "lr_iris = lr_iris.fit(X, y)\n",
    "y_pred = lr_iris.predict(X)\n",
    "\n",
    "print(metrics.accuracy_score(y_pred,y))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV to tune the model\n",
    "\n",
    "Now let us try GridSearchCV with saga and multinomial option\n",
    "\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Write code to use GridSearchCV to figure out the best parameters for C,max_iter and penalty from the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": [
     "s1",
     "l1",
     "ans"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "penalty = ['l1','l2']\n",
    "max_iter=[80, 100,140]\n",
    "C = np.linspace(0.1, 1.0, num=5)\n",
    "\n",
    "# Write your code below\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution\n",
    "\n",
    "```python\n",
    "param_grid = dict(max_iter=max_iter, C=C, penalty=penalty)\n",
    "\n",
    "lr_iris = LogisticRegression(multi_class='multinomial',solver='saga')\n",
    "\n",
    "grid = GridSearchCV(estimator=lr_iris, param_grid=param_grid, cv = 5)\n",
    "\n",
    "start_time = time.time()\n",
    "grid_result = grid.fit(X, y)\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the above the best parameters for the multiclass is below:\n",
    "\n",
    "```python\n",
    "Best: 0.986667 using {'C': 0.325, 'max_iter': 100, 'penalty': 'l2'}\n",
    "```\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Create LogisticRegression model with the best parameters from the GridSearchCV in the previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "#### Solution\n",
    "\n",
    "```python\n",
    "lr_iris = LogisticRegression(multi_class='multinomial',solver='saga', C=0.325, max_iter= 100, penalty= 'l2')\n",
    "lr_iris = lr_iris.fit(X, y)\n",
    "y_pred = lr_iris.predict(X)\n",
    "\n",
    "print(metrics.accuracy_score(y_pred,y))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "executed_sections": [],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
