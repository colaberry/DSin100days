{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In last notebook we covered some core definitions that were required to talk about statistics. The idea of population and sampling processes and the idea of standard error are crucial to understand statistics. The difference between how we treat sample and population, as you will see from here on out, will form the basis of understanding statistics. \n",
    "\n",
    "In this notebook, we add a new idea to this. We start by looking at elements of statistical estimation theory. We will be breaking statistical estimation theory down into elementary and advanced sections. In this notebook, we shall cover the elementary parts. After we introduce random variables and probability we shall delve more into advanced estimation theory ideas like maximum likelihood estimation or maximum apriori estimate and many more. What we shall do is introduce the general ideas of point and interval estimates and then move onto confidence intervals. Hence our sections are -\n",
    "\n",
    "1) Point estimates and Interval estimates <br>\n",
    "2) Confidence intervals<br>\n",
    "3) Visualization of confidence intervals<br>\n",
    "\n",
    "This already quite a bit. So lets get started. \n",
    "\n",
    "Before we start talking about estimates, lets define a few things so we can talk about estimates easily- <br>\n",
    "\n",
    "1) Population parameters - Parameters that pertain to the population like the population mean $\\mu$ or population standard deviation  $\\sigma$\n",
    "\n",
    "2) Sample parameters  - Parameters pertaining the sample, for example sample mean is denoted by $\\bar x$ and the  sample standard deviation is denoted  as $s$\n",
    "\n",
    "3) Sampling distribution parameters  - These parameters pertain to the sampling distribution that we introduced in the last notebook where the mean of the sampling distribution of means is denoted by $\\bar \\mu$ and the standard error which is the standard deviation of the sampling distribution is denoted as $\\bar \\sigma$\n",
    "\n",
    "If you ever get confused about what each term means in the later part of the notebook, you can always come back here and clarify doubts. \n",
    "\n",
    "\n",
    "# Point estimate and Interval Estimates\n",
    "\n",
    "Firstly, let's delve into why do we even need to talk about estimate. The whole point of understanding estimates is to provide better information about measurements we are making. Let us take an example of measuring the weight of Diljit. When we say that Diljit weighs 50 kg, we are making a point estimate about his weight. But we can say that Diljit weighs 50 kg $\\pm$ 5 kg. This is an example of an interval estimate. In general,  we prefer interval estimates over point estimates. Want to hazard a guess as to why? \n",
    "\n",
    "Question:  Why do you think interval estimates are better than point estimates? Hint: How much information is being provided by interval estimates vs point estimates.\n",
    "\n",
    "Answer: The answer is really in the hint. An interval estimate provides us with more information compared to a point estimate. It gives us not just what the value of a measurement but also how much error can there be in the value. Typically when we deal with any kind of measurement, we will always have an error range. From a tape measure to a weighing scale to any kind of measuring tool will always have an inherent range in which we can measure. \n",
    "\n",
    "Keeping this in mind, we can think of confidence interval as type of interval estimate. Unlike a point estimate which provides an estimate of a population parameter, a confidence interval provides a range of values in which the population parameter may lie. For this its better that we try to do this with an example. Things will be more clear. \n",
    "\n",
    "Suppose we take the example of Diljit's weight. Say the true distribution of the error of Diljit's weight on the weighing scale is given by the plot below - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:28:51.164611Z",
     "start_time": "2018-12-15T00:28:51.034930Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just run the code below\n",
    "\n",
    "# All libraries that would be used in this notebook\n",
    "import numpy as np \n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from IPython.display import display, Math\n",
    "\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from scipy.stats import norm \n",
    "from bokeh import plotting as pl\n",
    "from bokeh.models import HoverTool\n",
    " \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "random.seed = 1\n",
    "mean= 50\n",
    "std =0.5\n",
    "weight_dist = np.random.normal(mean, std, 10000)\n",
    "count, bins= np.histogram(weight_dist, 50)\n",
    "\n",
    "tools_to_show= 'box_zoom,pan,save,hover,reset,tap,wheel_zoom'        \n",
    "\n",
    "fig = pl.figure(x_range=[45,55], plot_height=250, tools = tools_to_show,title=\"Diljit's weight\" , x_axis_label= \"Diljit's Weight [kg]\", y_axis_label =\"Count\" )\n",
    "\n",
    "fig.vbar(x= bins[:-1], top= count, width = 0.02 )\n",
    "\n",
    "fig.xgrid.grid_line_color = None\n",
    "fig.y_range.start = 0\n",
    "\n",
    "hover = fig.select(dict(type=HoverTool))\n",
    "hover.tooltips = [(\"xvalue\", \"@x\"), (\"yvalue\", \"@top\")]\n",
    "\n",
    "show(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above we have used the bokeh plotting library to generate a frequency distribution of Dilijit's weight. \n",
    "\n",
    "We can  consider this distribution as a population which contains all the possible measurements of Diljit's weight. Now this population has many parameters, two of which are the population mean $\\mu$ and the population standard deviation $\\sigma$. Since the measurements lead to normal distribution we can say that mean of the population distribution is at $\\mu $ = 50 kg and the standard deviation is 0.5 kg. \n",
    "\n",
    "Suppose we have a situation that we don't have access to this population data about Diljit's weight and we want to infer what could be his weight? Firstly we are going to have a sample from this distribution. \n",
    "\n",
    "Question: With a sample size of 10 samples from the distribution about a 1000 times, plot the sampling distribution of mean.\n",
    "\n",
    "(Run the below code to observe the answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:28:51.597448Z",
     "start_time": "2018-12-15T00:28:51.166576Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just run the below code\n",
    "\n",
    "#Answer \n",
    "# so first we take the variable weight_dist and randomly sample from it \n",
    "\n",
    "number_times = np.arange(0,1000)\n",
    "sample_size = 10\n",
    "samples= [random.sample(list(weight_dist),sample_size) for x in number_times] \n",
    "sampling_distribution_mean  =[np.mean(x) for x in samples]\n",
    "count_mean, bins_mean = np.histogram(sampling_distribution_mean,50)\n",
    "# normalization \n",
    "count_mean_normalized = count_mean/sum(count_mean)\n",
    "\n",
    "\n",
    "# plotting \n",
    "fig = pl.figure(x_range=[48,52], plot_height=300, tools = tools_to_show,title=\"Sampling distribution of means\" , x_axis_label= \"mean weight [kg]\", y_axis_label =\"Count\" )\n",
    "\n",
    "fig.vbar(x= bins_mean[:-1], top= count_mean_normalized, width = 0.01 )\n",
    "\n",
    "fig.xgrid.grid_line_color = None\n",
    "fig.y_range.start = 0\n",
    "\n",
    "hover = fig.select(dict(type=HoverTool))\n",
    "hover.tooltips = [(\"xvalue\", \"@x\"), (\"yvalue\", \"@top\")]\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:28:51.674216Z",
     "start_time": "2018-12-15T00:28:51.599448Z"
    },
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we have a discrete distribution which represents the sampling distribution of mean.\n",
    "\n",
    "Question : What did we actually do in calculating the sampling distribution?\n",
    "\n",
    "Answer: What we have essentially done is weigh Dilijit about 10 times. We have done this 100 times. Its the equivalent of say weighing Diljit 10 times a day for 100 days to collect data. We do this because we want to understand what the variation in the measurement of the weight is. \n",
    "\n",
    "Now that we have this information, how can we estimate what is the population mean from this Diljit's weights? Well we have all the sample means, in fact we have a distribution of sample means. So we can look at the mean of the sampling distribution and compare it to the mean of the population distribution. So that would be - <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:28:51.690199Z",
     "start_time": "2018-12-15T00:28:51.676209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just run the below code\n",
    "\n",
    "mean_of_sampling_dist = np.mean(sampling_distribution_mean)\n",
    "population_mean =  bins[np.argmax(count)]\n",
    "\n",
    "print(\"population mean -  {}\" .format(round(population_mean,2)))\n",
    "print(\"mean of the the sampling distribution -  {}\".format(round(mean_of_sampling_dist,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T22:24:25.795794Z",
     "start_time": "2018-12-11T22:24:25.789656Z"
    }
   },
   "source": [
    "We can see that both these values are very close. Well that good, our mean of the sampling distribution $\\bar\\mu$ is close to the population mean $\\mu_P$. \n",
    "\n",
    "Of course all of this was possible since we had a sampling distribution.\n",
    "\n",
    "Next, we figure out what is the error in the sampling distribution. Why this is important ? Because it helps us quantify what is the variation in the sampling distribution. If that variation is really large than it means that there is a large error in $\\bar\\mu$ and this is bad because this is our estimate of the population mean $\\mu_P$. \n",
    "\n",
    "We have actually quantified the error in the sampling distribution before, its nothing but the standard error $\\bar\\sigma$. Wait, but if we want to look at the variation in the sampling distribution, why didn't we just use the standard deviation of the sampling distribution?  Well the standard deviation of the sampling distribution of means is the standard error. This we established the last notebook. Now we are utilizing that fact here to actually describe the sampling distribution. \n",
    "\n",
    "#  Confidence Intervals\n",
    "The other way we can describe the sampling distribution of means is using confidence intervals. Here we are not saying that there is a single value for the error but that the mean of the sampling distribution of means lies within a certain interval. We define the confidence intervals in terms of \"distance\" from the mean. So for instance we can say that we are confident that- \n",
    "\n",
    "\n",
    "<br>\n",
    "68.27% of our value of $\\bar\\mu$ falls within $\\bar\\mu \\pm \\bar\\sigma$\n",
    "\n",
    "<br>\n",
    "95.45% of our value of $\\bar\\mu$ falls within $\\bar\\mu \\pm 2\\bar\\sigma$\n",
    "\n",
    "<br>\n",
    "99.73% of our value of $\\bar\\mu$ falls within $\\bar\\mu \\pm 3\\bar\\sigma$\n",
    "\n",
    "Well that seems rather magical. How did we get these numbers. Well for that lets go back to a our good old normal distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:28:54.261818Z",
     "start_time": "2018-12-15T00:28:51.692167Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just run the below code\n",
    "\n",
    "xrange =np.linspace(-5,5,10000)\n",
    "pdf = norm(0,1).pdf(xrange)\n",
    "data = [go.Scatter(x = xrange, y = pdf, mode =\"lines\")]\n",
    "layout = go.Layout(title=\"Sampling distribution of mean\", xaxis = {\"title\": \"x values\",\n",
    "                                                                        \"range\": [-5,5]}\n",
    "                                                            , yaxis= {\"title\": \"PDF\" ,         \n",
    "                                                                       \"range\": [0,0.5]         \n",
    "                                                                                })\n",
    "figure = go.Figure(data = data, layout = layout)\n",
    "iplot(figure,filename = \"Normal distribution\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T00:51:13.281281Z",
     "start_time": "2018-12-12T00:51:13.272303Z"
    }
   },
   "source": [
    "What I have done here is just used the scipy stats module function called norm. norm.pdf(). It takes either an array or a single value and gives us value of the normal distribution. Now, those numbers 68.27 %, 95.45 % etc are essentially the area under the curve for $\\bar\\mu \\pm \\bar\\sigma$, $\\bar\\mu \\pm 2\\bar\\sigma$ and so on respectively. So how do we do this. We would have to write a piece of code that calculates this area. OR we can use the cumulative distribution for a normal distribution to get these percentages. Luckily for us scipy has a module for this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:28:54.278772Z",
     "start_time": "2018-12-15T00:28:54.264810Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just run the below code\n",
    "\n",
    "# for a single standard deviation away fromt the sample mean\n",
    "first_confidence_interval = (norm.cdf(1) -norm.cdf(-1))*100\n",
    "second_condifidence_interval = (norm.cdf(2) -norm.cdf(-2))*100\n",
    "third_condifidence_interval = (norm.cdf(3) -norm.cdf(-3))*100\n",
    "print(\"confidence interval values -> {} {} {} \".format(first_confidence_interval, \n",
    "                                                       second_condifidence_interval,\n",
    "                                                       third_condifidence_interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T19:29:49.275233Z",
     "start_time": "2018-12-12T19:29:49.268251Z"
    }
   },
   "source": [
    "We can actually build a table of confidence interval values based on standard deviation values. To do this let's first write down a general way of coming up with confidence intervals -\n",
    "\n",
    "confidence interval = $\\bar\\mu \\pm z\\bar\\sigma$\n",
    "\n",
    "where $z$ is called the confidence coefficient or the critical value based on the use case. $z$ is nothing fancy, for example when z = 1 i.e we are 1 standard deviation away from the mean, the confidence interval is 95.45 %. Now z can be any real number, but since $z \\approx 3$ is 99% of the area under the normal we don't always have to go above it. So following this logic lets build a calcuator for confidence intervals\n",
    "\n",
    "Question: For a normal distribution with $\\mu =0$ and $\\sigma =1$ get values of the confidence interval for z values between 0 to 3 in increments of 0.1. Plot these using either plotly or bokeh. Label the axis appropriately. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:29:45.168896Z",
     "start_time": "2018-12-15T00:29:45.062186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just run the below code\n",
    "\n",
    "#answer\n",
    "z_values  = np.arange(0,3.1,0.1)\n",
    "confidence_intervals  = [(norm.cdf(x) -norm.cdf(-x))*100 for x in z_values]\n",
    "\n",
    "\n",
    "fig = pl.figure(x_range=[0,3], plot_height=400, tools = tools_to_show,title=\"Confidence Intervals\" , x_axis_label= \"z-values\", y_axis_label =\"Confidence interval\" )\n",
    "\n",
    "fig.line(x=z_values, y= confidence_intervals )\n",
    "fig.xgrid.grid_line_color = None\n",
    "fig.y_range.start = 0\n",
    "\n",
    "hover = fig.select(dict(type=HoverTool))\n",
    "hover.tooltips = [(\"xvalue\", \"@x\"), (\"yvalue\", \"@y\")]\n",
    "\n",
    "\n",
    "\n",
    "show(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here I would like to get a bit philosophical. What does this number of  confidence interval 95.45 % mean? Does that mean that the probability that our population mean lies within 2 standard deviations of the the sampling distribution? NO. See, a confidence interval is really giving you an interval estimate of the error in your sampling method which is represented by the sampling distribution. See when we calculated the confidence intervals, we never used any information about the population mean. Hence to say that the population mean lies within 95.45 % of the sampling distribution would be an incorrect statement. For us to do that we need to use Bayesian methods of estimation. A topic beyond the scope of this current section. We will get there. For now, remember that the confidence intervals are error estimates for the sampling method that you are using and not probabilities. \n",
    "\n",
    "# Visualization of confidence intervals \n",
    "\n",
    "Lastly we have built a visualization for you showing the confidence interval for a given z value. the red region is essentially the area under the curve. Change the z value on the slide and hit run interact to play around with the visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:28:54.792394Z",
     "start_time": "2018-12-15T00:28:48.378Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Just run the below code\n",
    "\n",
    "# normal distribution of bokeh\n",
    "\n",
    "conf_int =0 \n",
    "\n",
    "\n",
    "def get_z(z_value): \n",
    "    fig = pl.figure(x_range=[-5,5], plot_height=400, tools = tools_to_show,title=\"Sampling distribution of means\" , x_axis_label= \"mean weight (kg)\", y_axis_label =\"Count\" )\n",
    "\n",
    "    fig.line(x=xrange, y= pdf, line_width = 4)\n",
    "\n",
    "    fig.xgrid.grid_line_color = None\n",
    "    fig.y_range.start = 0\n",
    "    hover = fig.select(dict(type=HoverTool))\n",
    "    hover.tooltips = [(\"xvalue\", \"@x\"), (\"yvalue\", \"@y\")]\n",
    "\n",
    "    shade_x = np.arange(-z_value,z_value,0.001)\n",
    "    shade_region=norm.pdf(shade_x)\n",
    "    shade_region[0] = 0 \n",
    "    shade_region[-1] = 0\n",
    "    fig.patch(shade_x, shade_region, color=\"red\", alpha =0.4)\n",
    "     \n",
    "    show(fig)\n",
    "\n",
    "    return z_value\n",
    "\n",
    "\n",
    "def conf_interval(z_value): \n",
    "    z = get_z(z_value )\n",
    "    conf_int = (norm.cdf(z)-norm.cdf(-z))*100\n",
    "    print(\"Confidence interval {} %\".format(round(conf_int,2)))\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "interact_manual(conf_interval, \n",
    "                z_value=widgets.FloatSlider(value =0.5,\n",
    "                                            min = 0.1,\n",
    "                                            max =3.0,\n",
    "                                            continuous_update = False),\n",
    "                );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T04:06:10.271311Z",
     "start_time": "2018-12-13T04:06:10.265330Z"
    }
   },
   "source": [
    "With that we shall be wrapping up this notebook. I hope that you have developed a base understanding for what confidence intervals are. If not it would be great to go through the notebook again and attempt some of the labs to gain a better understanding. \n",
    "\n",
    "The next topic we are going to cover is one of the most important topics in statistics. So get ready for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T00:50:11.080521Z",
     "start_time": "2018-12-07T00:50:10.879060Z"
    },
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# No exercise\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
