{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the below code to import all libraries required to run sample code within this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:00:54.740947Z",
     "start_time": "2019-01-09T23:00:45.763940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"de29772c-2f64-4ccc-a79b-feccc2ce3f32\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"de29772c-2f64-4ccc-a79b-feccc2ce3f32\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"de29772c-2f64-4ccc-a79b-feccc2ce3f32\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'de29772c-2f64-4ccc-a79b-feccc2ce3f32' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.16.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"de29772c-2f64-4ccc-a79b-feccc2ce3f32\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"de29772c-2f64-4ccc-a79b-feccc2ce3f32\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"de29772c-2f64-4ccc-a79b-feccc2ce3f32\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'de29772c-2f64-4ccc-a79b-feccc2ce3f32' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.16.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"de29772c-2f64-4ccc-a79b-feccc2ce3f32\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    " \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, Math\n",
    "\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from scipy.stats import norm \n",
    "from bokeh import plotting as pl\n",
    "from bokeh.models import HoverTool, Arrow, OpenHead, NormalHead, VeeHead\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "output_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next topic is something that seems simple on the surface but there is a lot of depth to it. In learning ANOVA which is an acronym for analysis of variance, we are trying to really solve a simple problem. Given two or more groups of data, can you conclude if the means are the same for all groups to which the data belongs or not. For example, you might have two groups like young people and old people, for which you are measuring how long do they watch the telly. You just want to see if there is a significant difference in the number of hours they watch. So to see if they are different, you would do a one way anova test. So in this notebook we are going to do the following: \n",
    "\n",
    "1) One way Anova- the easy way <br>\n",
    "2) One way Anova- the hard way <br>\n",
    "3) Two way Anova-  a simple example<br>\n",
    "\n",
    "\n",
    "## One way Anova\n",
    "\n",
    "As mentioned Anova is an acronym for analysis of variance of variable.\n",
    "\n",
    "When do we use Anova? We have stated earlier that anova is used when we want to compare means between groups, this actually takes an interesting form when it comes to datasets. Suppose we have a categorical variable and a continuous variable, like age group(young, middle, old) and height of individuals. We can treat the levels of the categorical variable age as separate groups and measure if the mean height is the same in all groups or not. Why is this important? Well if you are solving a machine learning problem, and you want to predict the height of individuals, and you use age as variable to predict the height then you will find that if the means of the groups in the age are the same then the height may actually not vary much by age. In which case you will not be able to teach a computer to predict height from age. In reverse, you *want* a difference in mean between the various groups of a categorical variable. This variation is what the computer learns when you run an ML algorithm. Very loosely you can say that there may be a dependency of the height on your categorical variable age. That is what we are after! \n",
    "\n",
    "If the above though seemed really confusing, just hold on, you will see what I mean! \n",
    "\n",
    "Anova is also another kind of hypothesis test, meaning we follow the sample logic of the hypothesis testing. In the last section, when we did chi-square testing we used the chi-square distribution and we defined the chi-square test statistic right. Here, we use the F-distribution and the F-statistic as the test statistic. We are essentially going to see if our null hypothesis is valid or not using the F-distribution. Similar to the lesson on  chi-square testing, we are not going to go in depth into about how you get the F-distribution but, we are straight going to applications. Also unlike the chi-square lesson, we are going to actually generate data, some fake data.   So what does it involve ? Well here are the steps in Anova: \n",
    "\n",
    "1) Define the null and the alternate hypothesis  <br>\n",
    "2) Set the significance level <br>\n",
    "3) Calculate the f-statistic <br>\n",
    "4) Calculate the p-value <br>\n",
    "5) Compare the p-value and significance level to conclude if the null hypothesis is valid or not <br>\n",
    "\n",
    "\n",
    "You will see these steps are pretty much similar to the lesson on hypothesis testing notebook or the chi-square testing. \n",
    "\n",
    "For this problem we will not use real data, we will create our own data. This is because of the kind of assumptions that go behind doing an anova: \n",
    "\n",
    "Assumptions- \n",
    "1) Normality: The data in each level of a category should be approximately normal. In the data of age vs number of hours of telly watched, the assumption is that in each category, i.e young, middle-aged and old, the number of hours of tv watched has a normal distribution. \n",
    "\n",
    "2) Homogeneity of variance: Assumption that the variance within each group should be similar to the other groups \n",
    "\n",
    "3) Sample size: Typically the expectation is that you have 20 samples \n",
    "\n",
    "4) Independence of Observations: The values from one group must be independent from other groups. This is a rather hard condition to meet, one we will worry about a bit less. \n",
    "\n",
    "Rather than trying to find a dataset that meets this criteria. We will merely pull data from a normal distribution and run Anova. This is more instructive since we can show various cases with this rather than merely depending on one case. \n",
    "\n",
    "The null hypothesis and alternate hypothesis, are pretty clear. \n",
    "\n",
    "Null hypothesis: The means of all groups are equal \n",
    "\n",
    "Alternate hypothesis : The means of all the groups are not equal. \n",
    "Note: It's not really telling us which means are not equal to the other means. Just that the null hypothesis is not valid\n",
    "\n",
    "\n",
    "Our first example is a really simple one. We are going to pull some data from a normal distribution, provide some context, then run Anova on it. Then we will do the whole calculation by hand. For simplicity, we will use a categorical variable with just 2 groups. \n",
    "\n",
    "Suppose we have two groups of people - young and old. We measure the amount of telly  they watch per week and get the following data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:00:54.774431Z",
     "start_time": "2019-01-09T23:00:54.745024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([28.12172682, 16.94121793, 17.35914124, 14.63515689, 24.32703815,\n",
       "         8.49230652, 28.72405882, 16.1939655 , 21.59519548, 18.75314812,\n",
       "        27.31053969,  9.69929645, 18.38791398, 18.07972823, 25.66884721,\n",
       "        14.50054366, 19.13785896, 15.61070791, 20.21106873, 22.91407607]),\n",
       " array([27.91621076, 29.71866586, 19.31901952, 38.20135404, 21.03282207,\n",
       "        25.79126317, 32.51440709, 23.77355957, 24.71023891, 25.45496193,\n",
       "        32.75727022, 41.46104006, 30.20769696, 24.41037277, 32.6952916 ,\n",
       "        27.0192015 , 29.90434752, 35.8750061 , 26.26064525, 30.04512625]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just run the below code\n",
    "\n",
    "np.random.seed(1)\n",
    "old_people_mean  = 20,\n",
    "old_people_sigma = 5\n",
    "old_count = 20\n",
    "old_tv_times = np.random.normal(old_people_mean, old_people_sigma, old_count)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "young_people_mean  = 30,\n",
    "young_people_sigma = 5\n",
    "young_count = 20\n",
    "young_tv_times = np.random.normal(young_people_mean, young_people_sigma, young_count)\n",
    "\n",
    "old_tv_times, young_tv_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, from above code we have randomly pulled 20 samples of data each for group of old people and group of young people. In this next step, we will create a dataframe where we categorically mark each of these sample observations as belonging to group 1 - old people and group 2 - young people. So, the first column (after the index) of the dataframe, will indicate age_class which is 1 for old and 2 for young people and the second column will contain the observations within each of those categories which we generated in the above exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:00:54.812303Z",
     "start_time": "2019-01-09T23:00:54.796011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_class</th>\n",
       "      <th>tv_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28.121727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.941218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.359141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.635157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>24.327038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.492307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28.724059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.193965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.595195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.753148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>27.310540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.699296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.387914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.079728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.668847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.500544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.137859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.610708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.211069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.914076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>27.916211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>29.718666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>19.319020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>38.201354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.032822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.791263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>32.514407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.0</td>\n",
       "      <td>23.773560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>24.710239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.454962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.0</td>\n",
       "      <td>32.757270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.0</td>\n",
       "      <td>41.461040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.0</td>\n",
       "      <td>30.207697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.0</td>\n",
       "      <td>24.410373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.0</td>\n",
       "      <td>32.695292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.0</td>\n",
       "      <td>27.019202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.0</td>\n",
       "      <td>29.904348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.0</td>\n",
       "      <td>35.875006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2.0</td>\n",
       "      <td>26.260645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.0</td>\n",
       "      <td>30.045126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age_class   tv_times\n",
       "0         1.0  28.121727\n",
       "1         1.0  16.941218\n",
       "2         1.0  17.359141\n",
       "3         1.0  14.635157\n",
       "4         1.0  24.327038\n",
       "5         1.0   8.492307\n",
       "6         1.0  28.724059\n",
       "7         1.0  16.193965\n",
       "8         1.0  21.595195\n",
       "9         1.0  18.753148\n",
       "10        1.0  27.310540\n",
       "11        1.0   9.699296\n",
       "12        1.0  18.387914\n",
       "13        1.0  18.079728\n",
       "14        1.0  25.668847\n",
       "15        1.0  14.500544\n",
       "16        1.0  19.137859\n",
       "17        1.0  15.610708\n",
       "18        1.0  20.211069\n",
       "19        1.0  22.914076\n",
       "20        2.0  27.916211\n",
       "21        2.0  29.718666\n",
       "22        2.0  19.319020\n",
       "23        2.0  38.201354\n",
       "24        2.0  21.032822\n",
       "25        2.0  25.791263\n",
       "26        2.0  32.514407\n",
       "27        2.0  23.773560\n",
       "28        2.0  24.710239\n",
       "29        2.0  25.454962\n",
       "30        2.0  32.757270\n",
       "31        2.0  41.461040\n",
       "32        2.0  30.207697\n",
       "33        2.0  24.410373\n",
       "34        2.0  32.695292\n",
       "35        2.0  27.019202\n",
       "36        2.0  29.904348\n",
       "37        2.0  35.875006\n",
       "38        2.0  26.260645\n",
       "39        2.0  30.045126"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just run the below code\n",
    "\n",
    "age_variable = np.append(np.repeat(1,20),np.repeat(2,20))  \n",
    "age_tv_times = pd.DataFrame([age_variable,np.append(old_tv_times,young_tv_times)]).T\n",
    "\n",
    "age_tv_times.columns =np.array([\"age_class\", \"tv_times\"])\n",
    "age_tv_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:00:54.895189Z",
     "start_time": "2019-01-09T23:00:54.814298Z"
    },
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One way anova- The easy way \n",
    "\n",
    "If you care only about implementing anova without really caring what it is. Then go ahead and just follow the method here. If you are coming to this topic for the very first time and have no idea what is anova, I would strongly advise that you go through the next section. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:00:55.300246Z",
     "start_time": "2019-01-09T23:00:54.896212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   sum_sq    df          F    PR(>F)\n",
      "C(age_class)   925.491762   1.0  29.419906  0.000004\n",
      "Residual      1195.404476  38.0        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Just run the below code\n",
    "\n",
    "model =ols( 'tv_times ~ C(age_class)', data= age_tv_times).fit()\n",
    "anova_results = sm.stats.anova_lm(  model, typ= 2)\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be wondering what on earth is the term \"tv_times ~ C(age_class)\" in the above code? Well you are going to have to wait a bit for a complete explanation. We need to cover linear regression and generalized linear models for that. For now, remember that for all practical purposes an anova is the same as a linear regression and that the term in question is a general formula of a line. Whenever you want to do a one way anova you would need to write a formula of a similar type. In a general sense, we have to write: \n",
    "\n",
    "\" output variable ~ C(input_variable)\" \n",
    "\n",
    "We generate a model object and then use the 'stats.anova_lm' function in the 'statsmodels' module to calculate the anova result. As you can see in the results section, we have a p-value and F value as well. So if we follow our hypothesis method then all we have to do now is say- p-value $\\lt$ significance level of 5% hence we can say that that the means of our two groups are not equal. Hey we are done ! \n",
    "\n",
    "Well that was uneventful. You can get all sorts of other information from the anova_results like the residual, sum squared value and the degrees of freedom. Well wait, what are those and why are they relevant? For that look at the next section! \n",
    "\n",
    "### One way Anova- the hard way \n",
    "\n",
    "In the last section, you saw how easy it is to get anova results in python. Once you know how do the calculation \"by hand\" its always better to use python packages to do the calculations since there are a lot of steps involved and it might just become a bit too tedious to do these steps. But for the very first time it is useful to see these steps. So let's go get on with it. \n",
    " \n",
    "When we are doing anova, what we are really doing is something called an f-test. For this, we will be using the f-statistic. The f-statistic is- \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "F= \\dfrac{\\text{variation between group means}}{\\text{variation in group means} } \n",
    "\\end{equation}\n",
    "\n",
    "we will decode each statement one at a time so let's start with it. \n",
    "\n",
    "Before we start with this. Lets do something, let's just plot the data to get an intuition as to how spread out the data looks and what should we expect. \n",
    "\n",
    "Question: Plot a plotly scatter plot with the dataframe age_tv_times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:00:57.306398Z",
     "start_time": "2019-01-09T23:00:55.305179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "markers",
         "name": "old",
         "type": "scatter",
         "uid": "af0820b0-5b4f-11e9-9903-b0359f561c51",
         "x": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "y": [
          28.12172681831621,
          16.941217931749623,
          17.35914123868272,
          14.635156889219147,
          24.327038146623394,
          8.492306515598587,
          28.7240588210824,
          16.193965495524488,
          21.595195480285494,
          18.75314812261295,
          27.31053968522487,
          9.69929645251173,
          18.387913979932463,
          18.07972822665792,
          25.66884721167719,
          14.500543663429845,
          19.137858962247822,
          15.610707910393142,
          20.211068733577964,
          22.91407606857911
         ]
        },
        {
         "mode": "markers",
         "name": "young",
         "type": "scatter",
         "uid": "af0820b1-5b4f-11e9-9903-b0359f561c51",
         "x": [
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2
         ],
         "y": [
          27.916210762972646,
          29.718665863868353,
          19.31901952165773,
          38.201354042024946,
          21.032822074025685,
          25.79126317171898,
          32.51440708579021,
          23.77355956696384,
          24.710238905688307,
          25.45496192536575,
          32.757270222732124,
          41.46104006407479,
          30.207696964992017,
          24.410372774432417,
          32.69529160290394,
          27.019201500967664,
          29.904347517394243,
          35.875006097501455,
          26.260645253530686,
          30.045126254866627
         ]
        }
       ],
       "layout": {
        "xaxis": {
         "dtick": 1,
         "range": [
          0,
          3
         ],
         "title": "Category"
        },
        "yaxis": {
         "range": [
          0,
          50
         ],
         "title": "Number of hours watching TV (hrs/week) "
        }
       }
      },
      "text/html": [
       "<div id=\"eddab52f-64a6-45f3-8cd4-711943a1e080\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            'eddab52f-64a6-45f3-8cd4-711943a1e080',\n",
       "            [{\"mode\": \"markers\", \"name\": \"old\", \"x\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"y\": [28.12172681831621, 16.941217931749623, 17.35914123868272, 14.635156889219147, 24.327038146623394, 8.492306515598587, 28.7240588210824, 16.193965495524488, 21.595195480285494, 18.75314812261295, 27.31053968522487, 9.69929645251173, 18.387913979932463, 18.07972822665792, 25.66884721167719, 14.500543663429845, 19.137858962247822, 15.610707910393142, 20.211068733577964, 22.91407606857911], \"type\": \"scatter\", \"uid\": \"af0820b0-5b4f-11e9-9903-b0359f561c51\"}, {\"mode\": \"markers\", \"name\": \"young\", \"x\": [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], \"y\": [27.916210762972646, 29.718665863868353, 19.31901952165773, 38.201354042024946, 21.032822074025685, 25.79126317171898, 32.51440708579021, 23.77355956696384, 24.710238905688307, 25.45496192536575, 32.757270222732124, 41.46104006407479, 30.207696964992017, 24.410372774432417, 32.69529160290394, 27.019201500967664, 29.904347517394243, 35.875006097501455, 26.260645253530686, 30.045126254866627], \"type\": \"scatter\", \"uid\": \"af0820b1-5b4f-11e9-9903-b0359f561c51\"}],\n",
       "            {\"xaxis\": {\"dtick\": 1, \"range\": [0, 3], \"title\": \"Category\"}, \"yaxis\": {\"range\": [0, 50], \"title\": \"Number of hours watching TV (hrs/week) \"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('eddab52f-64a6-45f3-8cd4-711943a1e080',{});}).then(function(){Plotly.animate('eddab52f-64a6-45f3-8cd4-711943a1e080');})\n",
       "        });</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"eddab52f-64a6-45f3-8cd4-711943a1e080\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            'eddab52f-64a6-45f3-8cd4-711943a1e080',\n",
       "            [{\"mode\": \"markers\", \"name\": \"old\", \"x\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"y\": [28.12172681831621, 16.941217931749623, 17.35914123868272, 14.635156889219147, 24.327038146623394, 8.492306515598587, 28.7240588210824, 16.193965495524488, 21.595195480285494, 18.75314812261295, 27.31053968522487, 9.69929645251173, 18.387913979932463, 18.07972822665792, 25.66884721167719, 14.500543663429845, 19.137858962247822, 15.610707910393142, 20.211068733577964, 22.91407606857911], \"type\": \"scatter\", \"uid\": \"af0820b0-5b4f-11e9-9903-b0359f561c51\"}, {\"mode\": \"markers\", \"name\": \"young\", \"x\": [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], \"y\": [27.916210762972646, 29.718665863868353, 19.31901952165773, 38.201354042024946, 21.032822074025685, 25.79126317171898, 32.51440708579021, 23.77355956696384, 24.710238905688307, 25.45496192536575, 32.757270222732124, 41.46104006407479, 30.207696964992017, 24.410372774432417, 32.69529160290394, 27.019201500967664, 29.904347517394243, 35.875006097501455, 26.260645253530686, 30.045126254866627], \"type\": \"scatter\", \"uid\": \"af0820b1-5b4f-11e9-9903-b0359f561c51\"}],\n",
       "            {\"xaxis\": {\"dtick\": 1, \"range\": [0, 3], \"title\": \"Category\"}, \"yaxis\": {\"range\": [0, 50], \"title\": \"Number of hours watching TV (hrs/week) \"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('eddab52f-64a6-45f3-8cd4-711943a1e080',{});}).then(function(){Plotly.animate('eddab52f-64a6-45f3-8cd4-711943a1e080');})\n",
       "        });</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trace1 = go.Scatter(\n",
    "    x = np.repeat(1,20),\n",
    "    y = old_tv_times,\n",
    "    mode = 'markers', \n",
    "    name =\"old\"\n",
    "    \n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = np.repeat(2,20),\n",
    "    y = young_tv_times,\n",
    "    mode = 'markers', \n",
    "    name=\"young\"\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        range=[0, 3], \n",
    "        title =\"Category\", \n",
    "        dtick =1\n",
    "       \n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        range=[0, 50], \n",
    "        title =\"Number of hours watching TV (hrs/week) \", \n",
    "        \n",
    "    )\n",
    ")\n",
    "data = [trace1, trace2]\n",
    "fig =go.Figure(data =data, layout= layout)\n",
    "iplot(fig, filename='tv-times-anova')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data we find that for group 1 the data is between $\\approx 8 $ and $ 30 $. Hover over the points to identify the group the point belongs to. For the young people class, is distributed between $\\approx 20 $ and $ 42 $. If we could just easily judge that the means are different then we really wouldn't need a test. For example if there were no overlapping points between the two sets of points then we do not have to even do a test. This is a case, just be looking at the data it's unclear but one can hazard the guess that maybe the means for both these groups are not the same.\n",
    "\n",
    "### So now on to the F-statistic\n",
    "\n",
    "#### Variation between the group means \n",
    "\n",
    "Firstly what we mean by the variation between group mean is the sum of squares by the degrees of freedom. \n",
    "\n",
    "we can nicely write it down as- \n",
    "\\begin{equation}\n",
    "\\text{ variation between group} = \\dfrac{\\text{sum of squares between groups}}{(K-1)} = \\dfrac{\\sum_{i=1}^K n_i (\\text{mean}_i - \\text{grand mean})^2 }{(K-1)} \n",
    "\\end{equation}\n",
    "\n",
    "where \n",
    "\n",
    "grand mean: mean of the whole column of tv_times for both levels of \"tv_times\" combined. Essentially mean of the column \"tv_times\" in the \"age_tv_times\" dataframe <br>\n",
    "\n",
    "$\\text{mean}_i$- is the mean of each the $i^{th}$ group. Notice the sum is from $i=1$ to $K$ \n",
    "\n",
    "$K$- refers to the number of groups. In our case $K =2$ \n",
    "\n",
    "$n_i$-  is the number of entries in the $i^{th}$ group, so this number is the same for both groups in our case. $n_1 =n_2 =20$\n",
    "\n",
    "$K- 1$- is also know as the degrees of freedom. Typically as df1. A second degrees of freedom value will come when we calculate the variation in group mean \n",
    "\n",
    "so let us calculate this now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:58:29.276084Z",
     "start_time": "2019-01-09T23:58:29.257134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variation between groups- 925.4917621802622\n"
     ]
    }
   ],
   "source": [
    "# variation between groups \n",
    "old_mean =np.mean(old_tv_times)\n",
    "young_mean=np.mean(young_tv_times)\n",
    "grand_mean = np.mean(age_tv_times.tv_times)\n",
    "num_samples =20 \n",
    "num_groups_K =2 \n",
    "df1 = (num_groups_K-1)\n",
    "sum_squares_between_groups= num_samples*(np.square(old_mean-grand_mean) + np.square(young_mean-grand_mean))\n",
    "variation_between_group = sum_squares_between_groups/df1\n",
    "print(\"Variation between groups- {}\".format(variation_between_group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare this value with what we acquired in the section- One way anova- the easy way. You will find that the values for sum_sq parameter is the same as the variation between group. This is good! We are on the right track. \n",
    "\n",
    "#### Variation within groups \n",
    "\n",
    "This one is a bit tricky.\n",
    "This involves two steps \n",
    "1) Sum up the difference between the group mean and individual values of the groups \n",
    "2) You will be doing the 1st step for all the groups involved, then sum these differences \n",
    "3) Divided it by the degrees of freedom. \n",
    "\n",
    "\n",
    "we can nicely write it down as- \n",
    "\\begin{equation}\n",
    "\\text{ variation within group} = \\dfrac{\\text{sum of squares within groups}}{(N-k)} = \\dfrac{\\sum_{i=1}^K \\sum_{j=1}^{N_g}  (\\text{value}_j - \\text{mean}_i)^2 }{(N-k)} \n",
    "\\end{equation}\n",
    "\n",
    "where \n",
    "\n",
    "$(N-k)$ - are the degrees of freedom where N is the total number values in all groups combined and k is the number of groups <br>\n",
    "$i$ - is the sum over all the groups  \n",
    "$j$ - is the sum over all the values in a group \n",
    "$\\text{value}_j$-  is the $j^{th}$ value in the $i^{th}$ group. For example $\\text{value}_5$ is the $5^{th}$ value in the group. \n",
    "\n",
    "So how should we proceed? Here are the steps\n",
    "\n",
    "1) Calculate the means for each group <br>\n",
    "2) Subtract each mean from the group values and then square them <br>\n",
    "3) Sum these squared values <br>\n",
    "4) Do steps 1-3 for all the groups then sum all the values <br>\n",
    "5) Divide by the degrees of freedom <br>\n",
    "\n",
    "Well, we already have the mean values for each group from the last section. Those are the \"old_mean\" and \"young_mean\" variables. So let's do this- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:44:10.191438Z",
     "start_time": "2019-01-09T23:44:10.180369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variation between groups- 31.45801251631027\n"
     ]
    }
   ],
   "source": [
    "# step 2 and 3 \n",
    "old_squared=np.sum(np.square(old_tv_times-old_mean))\n",
    "young_squared=np.sum(np.square(young_tv_times-young_mean))\n",
    "\n",
    "#step 4 \n",
    "sum_of_squares_within_groups = old_squared+young_squared\n",
    "\n",
    "#degrees of freedom \n",
    "df2 = len(age_tv_times) - 2 \n",
    "\n",
    "variation_within_group= sum_of_squares_within_groups/df2\n",
    "\n",
    "print(\"Variation between groups- {}\".format(variation_within_group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:52:37.216289Z",
     "start_time": "2019-01-09T23:52:37.211298Z"
    },
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we have everything. The last step is to execute what we have in equation(1), when we do that we get-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:55:25.695963Z",
     "start_time": "2019-01-09T23:55:25.690008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F value for is 29.419905714018505\n"
     ]
    }
   ],
   "source": [
    "F_value =  variation_between_group/variation_within_group\n",
    "print(\"F value for is {}\".format(F_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find that we acquired the same F value when we ran the anova analysis from statsmodel module. To get the p-value we can simply do. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T00:00:06.455448Z",
     "start_time": "2019-01-10T00:00:06.450254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value for the given F-value is 3.5082754100690394e-06\n"
     ]
    }
   ],
   "source": [
    "p_value = 1-stats.f.cdf(F_value,df1,df2)\n",
    "print(\"p value for the given F-value is {}\".format(p_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to what we did with the chi-square distribution, we subtract 1 from the probability value since we are looking at probability which is to the left of the critical value. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T00:06:30.910949Z",
     "start_time": "2019-01-10T00:06:30.640663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c0aa64716546779444c767f386c133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatText(value=5.0, description='significance_level', step=0.001), FloatText(value=5.0,"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_int = 0 \n",
    "xrange = np.linspace(0,10,10000)\n",
    "\n",
    "#answer\n",
    "tools_to_show= 'box_zoom,pan,save,hover,reset,tap,wheel_zoom'        \n",
    "\n",
    "\n",
    "\n",
    "def get_sig_lvl(significance_level,f_val_crtic, df1,df2): \n",
    "    xrange =np.linspace(0,f_val_crtic+5,10000)\n",
    "    pdf = stats.f.pdf(xrange, df1,df2)\n",
    "\n",
    "    fig = pl.figure(x_range=[0,f_val_crtic+5], \n",
    "                    plot_height=400,\n",
    "                    tools = tools_to_show,\n",
    "                    title=\"f square test calculator: Figure 1\",\n",
    "                    x_axis_label= \"f values\",\n",
    "                    y_axis_label =\"Probability distribution\")\n",
    "    \n",
    "    fig.line(x=xrange, y= pdf, line_width = 4)\n",
    "\n",
    "    fig.xgrid.grid_line_color = None\n",
    "    fig.y_range.start = 0\n",
    "    \n",
    "    hover = fig.select(dict(type=HoverTool))\n",
    "    hover.tooltips = [(\"xvalue\", \"@x\"), (\"yvalue\", \"@y\")]\n",
    "   \n",
    "#     # calculate right \n",
    "    z_value = stats.f.ppf(1-(significance_level)/100, df1,df2)\n",
    "\n",
    "#     # calculate pvalue \n",
    "    p_value = 1.0-stats.f.cdf(f_val_crtic,df1,df2)\n",
    "\n",
    "    show(fig)\n",
    "\n",
    "    print(\"z value for the given significance level: {} \".format(z_value))\n",
    "    print(\"p value  :  {}\".format(p_value))\n",
    "    return None \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "interact(get_sig_lvl, \n",
    "                 significance_level = widgets.FloatText(value = 5, \n",
    "                                                        min = 50,\n",
    "                                                        max = 99.9, \n",
    "                                                         step = 0.001), \n",
    "                   f_val_crtic = widgets.FloatText(value = 5, \n",
    "                                                        min = 0,\n",
    "                                                        max = 1000, \n",
    "                                                        step = 0.001),\n",
    "                  df1 = widgets.IntText(value = 3, \n",
    "                                                        min = 1,\n",
    "                                                        max = 100, \n",
    "                                                        step = 1),\n",
    "                 df2 = widgets.IntText(value = 2, \n",
    "                                                        min = 1,\n",
    "                                                        max = 100, \n",
    "                                                        step = 1)\n",
    "     \n",
    "        \n",
    "        );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just some Rough code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:00:57.350664Z",
     "start_time": "2019-01-09T23:00:57.337976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16.24345364,  -6.11756414,  -5.28171752, -10.72968622,\n",
       "          8.65407629]),\n",
       " array([  0.83242153,   4.43733173, -16.36196096,  21.40270808,\n",
       "        -12.93435585]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "mu  = 0,\n",
    "sigma = 10\n",
    "group1 = np.random.normal(mu, sigma, 5)\n",
    "\n",
    "np.random.seed(2)\n",
    "mu  = 5,\n",
    "sigma = 10\n",
    "group2 = np.random.normal(mu, sigma, 5)\n",
    "\n",
    "group1, group2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just some Rough code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:00:57.368616Z",
     "start_time": "2019-01-09T23:00:57.359645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=29.419905714018498, pvalue=3.5082754101159494e-06)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.f_oneway(old_tv_times, young_tv_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:00:57.393359Z",
     "start_time": "2019-01-09T23:00:57.377384Z"
    },
    "hide_input": true
   },
   "source": [
    "### Solution code\n",
    "\n",
    "```python\n",
    "# Just run the above code\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
