{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab : Pandas and Dataframes \n",
    "\n",
    "Pandas is the bread and butter for a Data Analyst or data scientists. We use pandas to load and transform data. Typically pandas is used to perform all the the exploratory data analysis. \n",
    "\n",
    "In this lab we will be working on two datasets. \n",
    "\n",
    "Part I: We will use the Iris Dataset, in part 2 we will use the grad student dataset, in part 3 we will use the titanic dataset. \n",
    "\n",
    "Lets start with the Iris dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# IRIS DATASET \n",
    "iris_dataset = load_iris()\n",
    "target = list(iris_dataset.target) \n",
    "dataset = list(iris_dataset.data)\n",
    "target_names = list(iris_dataset.target_names)\n",
    "feature_names = iris_dataset.feature_names\n",
    "\n",
    "\n",
    "# HEART DATASET \n",
    "heart_loc = \"../../../data/Heart.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the variable dataset make a dataframe. Remember when \n",
    "# when you have a list you need to do df = pd.DataFrame(data=list, columns=column_names)\n",
    "# where column_names is a list \n",
    "iris_df = \"####\"\n",
    "\n",
    "# Store the head of the iris_df, by deafualt the head stores 5 rows of data \n",
    "iris_head = \"####\"\n",
    "\n",
    "# You should get the exact values as show below \n",
    "print(\"The head of the iris dataset is \\n{}\".format(iris_head))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The head of the iris dataset is <br>\n",
    "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm) <br>\n",
    "0                5.1               3.5                1.4               0.2 <br>\n",
    "1                4.9               3.0                1.4               0.2 <br>\n",
    "2                4.7               3.2                1.3               0.2 <br>\n",
    "3                4.6               3.1                1.5               0.2 <br>\n",
    "4                5.0               3.6                1.4               0.2 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next create a dataframe for the variable target. This is similar to what you did above\n",
    "target_df = \"####\"\n",
    "\n",
    "print(\"Head of target dataframe is : \\n {}\".format(target_df.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head of target dataframe is : <br>\n",
    "    target <br>\n",
    "0       0 <br>\n",
    "1       0 <br>\n",
    "2       0 <br>\n",
    "3       0 <br>\n",
    "4       0 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to combine both the dataframes ```iris_df``` and ```target_df```. There are multiple ways of doing this in pandas. We will use the concat function here. You can read about it [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the concat function combine iris_df and target_df. Make sure you check \n",
    "# the axis along which you are combining the dataframes \n",
    "iris_combined_df = \"####\"\n",
    "\n",
    "print(\"Shape of the iris combine dataframe : {}\".format(iris_combined_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of the iris combine dataframe : (150, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next print the values in the 3rd row of the iris_combined_df \n",
    "third_row = iris_combined_df.iloc[2,:]\n",
    "\n",
    "print(\"Third row values : \\n{}\".format(third_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third row values : <br>\n",
    "sepal length (cm)    4.7 <br>\n",
    "sepal width (cm)     3.2 <br>\n",
    "petal length (cm)    1.3 <br>\n",
    "petal width (cm)     0.2 <br>\n",
    "target               0.0 <br>\n",
    "Name: 2, dtype: float64 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we want the third column in the dataset. Using iloc can you get the third column\n",
    "third_column = \"####\"\n",
    "print(\"Print the head of the third column is : \\n{}\".format(third_column.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the head of the third column is : <br>\n",
    "0    1.4 <br>\n",
    "1    1.4 <br>\n",
    "2    1.3 <br>\n",
    "3    1.5 <br>\n",
    "4    1.4 <br>\n",
    "Name: petal length (cm), dtype: float64 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose you want to change a single value in the dataframe i.e the value in a single cell of the dataframe. How would you do that? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the value of target in the 3rd row in the iris_combined_df from 0 to setosa \n",
    "\"####\"\n",
    "\n",
    "print(\"Print the third row of iris dataset : \\n{}\".format(iris_combined_df.iloc[3,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the third row of iris dataset : <br>\n",
    "sepal length (cm)       4.6 <br>\n",
    "sepal width (cm)        3.1 <br>\n",
    "petal length (cm)       1.5 <br>\n",
    "petal width (cm)        0.2 <br>\n",
    "target               setosa <br>\n",
    "Name: 3, dtype: object <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, let see how we can apply an operation the entire row or an entire column of a dataframe.  The next part is a bit on the challenging side since you will have to use a lambda function to modify the column. Our first task is that we have to convert all the values in the target column to names. All the values in target are either 0 1, or 2 save the third row which we changed to 'setosa'. Hence we now have a column which contains integer values 0,1,2 and string 'setosa' \n",
    "\n",
    "To get around this, we will use the apply function to the target column. Take a look at it (here)[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html]. Remember, we are applying this only to the target column not the rest of them. The argument of the apply function will be a lambda function like this: \n",
    "\n",
    "lambda x: use names_dict[x] if  string of x is a digit, if not return x\n",
    "\n",
    "Now, you will add this lambda function as an argument into apply. You can use isdigit() to check if the string is a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dict = {0: target_names[0], 1:target_names[1], 2: target_names[2]}\n",
    "\n",
    "# Convert all the values in the target column to names.\n",
    "# you can use the names in target_names for this purpose\n",
    "iris_combined_df['target'] = \"####\"\n",
    "print(\"Head of the target column : \\n{}\".format(iris_combined_df['target'].head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head of the target column : <br> \n",
    "0    setosa  <br> \n",
    "1    setosa  <br> \n",
    "2    setosa  <br> \n",
    "3    setosa  <br> \n",
    "4    setosa  <br> \n",
    "Name: target, dtype: object  <br> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method above may not be the most elegant way of doing this. You may find other ways that are better or eaiser. Next lets looks at applying an operation to the entire row. \n",
    "\n",
    "Suppose we want to take the square of all the elements in the first row. How would you do it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_copy  = iris_combined_df.copy()\n",
    "\n",
    "# Use iris copy and square the values of the first row\n",
    "# In order to do this you need to use iloc to select\n",
    "# the first row and 4 columns. To this you need to apply \n",
    "# a lambda function that will square the values\n",
    "squared_values =\"####\"\n",
    "\n",
    "print(\"Squared values of the first row are : \\n{}\".format(squared_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squared values of the first row are : <br> \n",
    "sepal length (cm)    26.01 <br>\n",
    "sepal width (cm)     12.25 <br>\n",
    "petal length (cm)     1.96 <br>\n",
    "petal width (cm)      0.04 <br>\n",
    "Name: 0, dtype: float64 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2  \n",
    "Next up we will be using the heart dataset. Details on the dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/heart+disease). The goal of the dataset is to predict the if a person has heart disease or not, to this end there are 13 features that can be used for this purpose. These features are a mix of continuous and categorical. Here we will explore the data using pandas\n",
    "\n",
    "Lets first start by import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the heart dataset by reading the csv file. the variable heart_loc contains path to the file\n",
    "heart_df =\"####\"\n",
    "\n",
    "heart_head = heart_df.head()\n",
    "\n",
    "print(\"Head of the heart dataset: \\n{}\".format(heart_head))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head of the heart dataset: <br>\n",
    "   Unnamed: 0  Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  \\ <br>\n",
    "0           1   63    1       typical     145   233    1        2    150   <br>\n",
    "1           2   67    1  asymptomatic     160   286    0        2    108   <br>\n",
    "2           3   67    1  asymptomatic     120   229    0        2    129   <br>\n",
    "3           4   37    1    nonanginal     130   250    0        0    187   <br>\n",
    "4           5   41    0    nontypical     130   204    0        2    172   <br>\n",
    "\n",
    "   ExAng  Oldpeak  Slope   Ca        Thal  AHD  <br>\n",
    "0      0      2.3      3  0.0       fixed   No  <br>\n",
    "1      1      1.5      2  3.0      normal  Yes  <br>\n",
    "2      1      2.6      2  2.0  reversable  Yes  <br>\n",
    "3      0      3.5      3  0.0      normal   No  <br>\n",
    "4      0      1.4      1  0.0      normal   No <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are dealing with a categorical variable it is a good idea to a count of how many rows of data you have for each category. You can easily do this by using the [```value_counts```](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html)(click it to go to page) function in pandas. You apply value counts to a single column from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the value counts to get the number of rows in checkPain column of the hearts dataset. \n",
    "ChestPain_counts = \"####\"\n",
    "\n",
    "print(\"Value counts of Chest Pain variable : \\n{}\".format(ChestPain_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value counts of Chest Pain variable : <br>\n",
    "asymptomatic    144 <br>\n",
    "nonanginal       86 <br>\n",
    "nontypical       50 <br>\n",
    "typical          23 <br>\n",
    "Name: ChestPain, dtype: int64 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we want just the different categories and not the values how can we extra them? \n",
    "# Hint: You can get the index of ChestPain_counts and convert it to a list\n",
    "chestpain_categories = \"####\"\n",
    "\n",
    "print(\"List of categories in the Categorical variable ChestPain : \\n{}\".format(chestpain_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of categories in the Categorical variable ChestPain : \n",
    "['asymptomatic', 'nonanginal', 'nontypical', 'typical']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There may be situations that you may want to convert the value counts to dict. \n",
    "# You can do that be attaching df.to_dict()\n",
    "chestpain_dict = \"####\"\n",
    "\n",
    "print(\"Dict of categories is : \\n{}\".format(chestpain_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dict of categories is : <br>\n",
    "{'asymptomatic': 144, 'nonanginal': 86, 'nontypical': 50, 'typical': 23}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "grade"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import Javascript\n",
    "display(Javascript(\"\"\"var nb = IPython.notebook;\n",
    "var kernel = IPython.notebook.kernel;\n",
    "console.log(nb)\n",
    "var command = \"nb_name = '\" + nb.notebook_path  + \"'\";\n",
    "kernel.execute(command);\n",
    "var command2 = \"user_id = '\" +/user\\/([^/]+)\\//.exec(Jupyter.notebook.base_url)[1] + \"'\"; \n",
    "\n",
    "kernel.execute(command2);\"\"\"))\n",
    "\n",
    "import requests\n",
    "from time import gmtime, strftime\n",
    "from IPython.display import clear_output\n",
    "\n",
    "user_ns = tuple(get_ipython().user_ns.items())\n",
    "user_id = ''\n",
    "lab_name = ''\n",
    "import os\n",
    "\n",
    "def display_result(result, res_code):\n",
    "    from IPython.display import display, HTML\n",
    "    js = \"<style>p.res {background-color: lightblue;} p.pas {color: green;text-align: center;font-size: 150%;} p.fail {color: red;text-align: center;font-size: 150%;}  p.wait {color: blue;text-align: center;font-size: 150%;} p.center {text-align: center;font-size: 200%;}</style>\"\n",
    "    if res_code == 'PASS':\n",
    "        #js = js + \"<script>$('#notebook-container').after('<p id=lastidp class=pas>%s</p>')</script>\"   % result\n",
    "        js = js + \"<script>$('#lastidp').replaceWith('<p id=lastidp class=pas>%s</p>')</script>)\"   % result\n",
    "    elif res_code == 'FAIL':\n",
    "        js = js + \"<script>$('#lastidp').replaceWith('<p id=lastidp class=fail>%s</p>')</script>\"   % result\n",
    "    else:\n",
    "        js = js + \"\"\"<script>\n",
    "        if($('#lastidp').length){\n",
    "        $('#lastidp').replaceWith('<p id=lastidp class=wait>%s</p>')\n",
    "        }else{\n",
    "        $('#notebook-container').after('<p id=lastidp class=wait>%s</p>')\n",
    "        }\n",
    "        </script>\n",
    "        \"\"\"   % (result,result)\n",
    "    display(HTML(js))\n",
    "\n",
    "display_result('','WAIT')\n",
    "    \n",
    "# if value_type == int:\n",
    "for name, value in user_ns:\n",
    "    if name == 'user_id':\n",
    "        user_id = value\n",
    "    if name == 'nb_name':\n",
    "        lab_name = value\n",
    "        lab_name = os.path.basename(lab_name).split('.')[0]\n",
    "\n",
    "input_content_file = lab_name + '.ipynb'\n",
    "\n",
    "import random\n",
    "n = random.randint(1001,3001)\n",
    "f = {'file': ( 'rnd' +  str(n) + '_' + input_content_file, open(input_content_file,'rb'))}\n",
    "d = {'user': user_id}\n",
    "r = requests.post('http://autograde.refactored.ai/uploader', data=d, files=f)\n",
    "#r = requests.post('http://localhost:5000/uploader', data=d, files=f)\n",
    "tm = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "msg = r.json()['result']['message'][0]\n",
    "res = r.json()['result']['result']\n",
    "answerid = r.json()['answerid']\n",
    "result = tm + ' - ' + msg + '    Answerid is : ' + str(answerid) \n",
    "#score = r.json()['result']['score']\n",
    "#result = tm + ' - ' + msg + '    Your result is : ' + res + '     And the score is : ' + str(score)\n",
    "#print(result)\n",
    "display_result(result,'WAIT')\n",
    "\n",
    "import time\n",
    "count = 0\n",
    "while True:\n",
    "    #r = requests.get('http://localhost:5000/get_result?answer_id=' + str(answerid))\n",
    "    r = requests.get('http://autograde.refactored.ai/get_result?answer_id=' + str(answerid))\n",
    "    res = r.json()['result']['result']\n",
    "    if res != 'WAIT':\n",
    "        tm = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "        msg = r.json()['result']['message'][0]\n",
    "        res = r.json()['result']['result']\n",
    "        score = r.json()['result']['score']\n",
    "        result = tm + ' - ' + msg + ',    Your result is : ' + res + '    And your score is : ' + str(score) \n",
    "        clear_output(wait=True)\n",
    "        break\n",
    "    else:\n",
    "        if(count ==0):\n",
    "            print('Waiting for your score......')\n",
    "        count = count + 1\n",
    "        time.sleep(10)\n",
    "        if(count > 10):\n",
    "            result = 'Error occurred during evaluation. Please resubmit.'\n",
    "            break\n",
    "\n",
    "display_result(result,res)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
